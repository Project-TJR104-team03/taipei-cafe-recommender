import pandas as pd
import json
import os
import logging
import tag_config as tc  # ç¢ºä¿ç›®éŒ„ä¸‹æœ‰ä½ çš„æ¨™ç±¤å®šç¾©

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class StageA_OneStop_Processor:
    def __init__(self, distilled_csv_path, official_baseline_path):
        """
        ä¸€ç«™å¼è™•ç†å™¨ï¼šç›´æ¥å¾ç´”åŒ– CSV ç”¢å‡º Vertex AI ä»»å‹™åŒ…
        """
        self.distilled_csv_path = distilled_csv_path
        self.official_baseline_path = official_baseline_path
        self.official_map = {}

    def _load_data(self):
        """è®€å– CSV è©•è«–èˆ‡å®˜æ–¹ JSON åŸºæº–"""
        if not os.path.exists(self.distilled_csv_path):
            logger.error(f"âŒ æ‰¾ä¸åˆ°ç´”åŒ–è©•è«–æª”: {self.distilled_csv_path}")
            return None
        
        # 1. è®€å–ç¬¬ä¸€éšæ®µç”¢å‡ºçš„ CSV
        df = pd.read_csv(self.distilled_csv_path)
        
        # 2. è®€å–å®˜æ–¹åŸºæº–ä¸¦å»ºç«‹ç´¢å¼• (Key: place_id)
        if os.path.exists(self.official_baseline_path):
            with open(self.official_baseline_path, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
                self.official_map = {item.get('place_id'): item for item in raw_data}
            logger.info(f"âœ… è¼‰å…¥å®˜æ–¹åŸºæº–ï¼Œå…± {len(self.official_map)} ç­†è³‡æ–™ã€‚")
        else:
            logger.warning(f"âš ï¸ æ‰¾ä¸åˆ°å®˜æ–¹åŸºæº–æª”: {self.official_baseline_path}")

        return df

    def _build_system_instruction(self):
        """AI 1 çš„åŠ‡æœ¬ï¼šæ•¸æ“šå¯©è¨ˆå“¡ (Data Auditor)"""
        return f"""
[SYSTEM_SPECIFICATION]
ROLE: Data_Auditor_Engine
TASK: Verify official claims against user reviews & Discover new features.
CONFIG: {tc.FEATURE_DEFINITION} / {tc.NORM_RULES}

[EXECUTION_LOGIC]
1. **Calibration (åŸºæº–æ ¡é©—)**: è‹¥ [Baseline] èˆ‡è©•è«–åš´é‡è¡çªï¼Œå¿…é ˆåœ¨ conflict_alerts æå‡ºä¿®æ­£ã€‚
2. **Incremental Discovery (å¢é‡ç™¼ç¾)**: æŒ–æ˜æ¨™ç±¤æ¸…å–®å¤–çš„ç‰¹è‰² (å¦‚ï¼šç‡•éº¥å¥¶ã€ç‰¹å®šä½æ¶ˆã€æ™¯è§€)ã€‚

[OUTPUT_SCHEMA]
Strict JSON only.
"""

    def generate_jsonl(self, output_file):
        """åŸ·è¡Œä¸€ç«™å¼å°è£èˆ‡è½‰æ›"""
        df = self._load_data()
        if df is None: return

        system_instruction = self._build_system_instruction()
        
        # æŒ‰ place_id åˆ†ç¾¤ï¼Œé€™å°±æ˜¯æˆ‘å€‘åŸæœ¬ Packer åœ¨åšçš„äº‹
        grouped = df.groupby('place_id')
        logger.info(f"ğŸš€ é–‹å§‹ç‚º {len(grouped)} å®¶åº—å®¶ç”Ÿæˆä¸€ç«™å¼ä»»å‹™å°åŒ…...")

        with open(output_file, 'w', encoding='utf-8') as f_out:
            count = 0
            for pid, group in grouped:
                place_name = group['place_name'].iloc[0]
                
                # [DATA JOIN] ç²å–è©²åº—å®˜æ–¹åŸºæº–
                baseline = self.official_map.get(pid, {"official_tags": {}, "features": {}})
                
                # æº–å‚™è©•è«–
                review_texts = "\n".join([f"- {r}" for r in group['content'].astype(str)])
                
                user_content = f"""
### [TARGET STORE]
Name: {place_name} (ID: {pid})
### [1. OFFICIAL BASELINE]
{json.dumps(baseline, ensure_ascii=False)}
### [2. USER REVIEWS]
{review_texts}
"""

                # å°è£ç‚º Vertex AI æ ¼å¼ [é—œéµä¿®æ­£ï¼šè­˜åˆ¥ç¢¼æ‰å¹³åŒ–]
                request_item = {
                    "request": {
                        "contents": [
                            {"role": "user", "parts": [{"text": f"System Instruction: {system_instruction}\n\nUser Content: {user_content}"}]}
                        ],
                        "generationConfig": { "response_mime_type": "application/json", "temperature": 0.0 }
                    },
                    "custom_id": str(pid),
                    "place_id": str(pid),
                    "place_name": str(place_name)
                }
                
                f_out.write(json.dumps(request_item, ensure_ascii=False) + '\n')
                count += 1

        logger.info(f"âœ… ä¸€ç«™å¼å°è£å®Œæˆï¼š{output_file} (å…± {count} ç­†)")

if __name__ == "__main__":
    CONFIG = {
        "distilled_csv_path": "reviews_top50_distilled.csv", # ç›´æ¥è®€å– Step 1 çš„ CSV
        "official_baseline_path": "cafe_data_final.json",
    }
    processor = StageA_OneStop_Processor(**CONFIG)
    processor.generate_jsonl("vertex_job_stage_a.jsonl")