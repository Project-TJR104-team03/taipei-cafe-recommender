# app/services/recommend_service.py
import logging
import traceback
from datetime import datetime
from geopy.distance import geodesic
from typing import Any, Dict, List, Optional

from database import db_client
from utils import is_google_period_open
from locations import ALL_LOCATIONS
from agents.intent_agent import IntentAgent
from google import genai 
from services.scoring import calculate_comprehensive_score
from constants import TAG_EMOJI_MAP


logger = logging.getLogger("Coffee_Recommender")

class RecommendService:
    def __init__(self, api_key: str):
        self.intent_agent = IntentAgent()
        if api_key:
            self.client = genai.Client(api_key=api_key)
        else:
            self.client = None

    def get_embedding(self, text: str) -> Optional[List[float]]:
        try:
            if not self.client: 
                logger.error("âŒ Gemini Client æœªåˆå§‹åŒ–")
                return None
            
            response = self.client.models.embed_content(
                model='models/gemini-embedding-001',
                contents=text,
                config={'task_type': 'RETRIEVAL_QUERY', 'output_dimensionality': 1536}
            )
            vector = response.embeddings[0].values
            
            if len(vector) == 1536:
                logger.info(f"âœ… [AI èªæ„åˆ†ææˆåŠŸ] å‘é‡ç¶­åº¦: 1536")
            else:
                logger.warning(f"âš ï¸ é æœŸç¶­åº¦ 1536ï¼Œä½†å›å‚³ç‚º {len(vector)}")
            return vector
        except Exception as e:
            logger.error(f"âŒ Embedding Error: {e}")
            return None

    async def recommend(self, lat: float, lng: float, user_id: str = None, 
                        user_query: str = None, cafe_tag: str = None,
                        rejected_place_id: str = None,  # ğŸŒŸ æ–°å¢ï¼šä½¿ç”¨è€…å‰›å‰›æ‹’çµ•çš„åº—å®¶ ID
                        negative_reason: str = None     # ğŸŒŸ æ–°å¢ï¼šä½¿ç”¨è€…æ‹’çµ•çš„åŸå› 
                        ) -> Dict[str, Any]:
        try:
            db = db_client.get_db()
            if db is None: return {"data": []}

            # ğŸ”¥æª¢æŸ¥åˆ°åº•æœ‰æ²’æœ‰æ”¶åˆ° user_query
            logger.info(f"ğŸ”¥ DEBUG: æ”¶åˆ° user_query = '{user_query}'")

            # ğŸ”¥ [çµ„å“¡æ–°å¢] === 1. åº§æ¨™æ ¡æ­£ (æ”¯æ´å–®é» & å¤šé»ä¸­é–“å€¼å®šä½) ===
            current_search_lat, current_search_lng = lat, lng
            search_query = user_query # è¤‡è£½ä¸€ä»½ï¼Œé¿å…æ”¹åˆ°åŸå§‹è³‡æ–™
            
            if search_query:
                found_coords = []
                
                # æƒææ‰€æœ‰å¯èƒ½çš„é—œéµå­—
                for loc_name, coords in ALL_LOCATIONS.items():
                    if loc_name in search_query:
                        found_coords.append(coords)
                        # ç§»é™¤åœ°åï¼Œé¿å…å¹²æ“¾å¾ŒçºŒå‘é‡æœå°‹ (ä¾‹å¦‚ "åŒ—è»Šä¸­å±±" -> "")
                        search_query = search_query.replace(loc_name, "").strip()
                
                # å¦‚æœæœ‰æ‰¾åˆ°åœ°é» (1å€‹æˆ–å¤šå€‹)
                if found_coords:
                    # ç®—å‡ºå¹³å‡ç¶“ç·¯åº¦ (ä¸­é–“é»)
                    avg_lat = sum([c[0] for c in found_coords]) / len(found_coords)
                    avg_lng = sum([c[1] for c in found_coords]) / len(found_coords)
                    
                    current_search_lat, current_search_lng = avg_lat, avg_lng
                    
                    loc_count = len(found_coords)
                    if loc_count > 1:
                        logger.info(f"ğŸ“ [åœ°é»åˆ‡æ›] åµæ¸¬åˆ° {loc_count} å€‹åœ°é»ï¼Œè¨ˆç®—ä¸­é–“é» -> ({avg_lat}, {avg_lng})")
                    else:
                        logger.info(f"ğŸ“ [åœ°é»åˆ‡æ›] é–å®šåœ°é» -> ({avg_lat}, {avg_lng})")

            # è™•ç†å‰©é¤˜å­—ä¸²ï¼šå¦‚æœåœ°åæ‹¿æ‰å¾Œåªå‰©ç©ºå­—ä¸²æˆ–ç„¡æ„ç¾©ç¬¦è™Ÿï¼Œè¦–ç‚º None
            # é€™æ¨£å°±æœƒè‡ªå‹•èµ° Path B (æ‰¾é™„è¿‘çš„åº—)
            if not search_query or len(search_query) < 2: 
                search_query = None

            user_loc = (current_search_lat, current_search_lng)

            
            # === 2. AI æ„åœ–åˆ†æ (æ™‚é–“éæ¿¾) ===
            filter_open_now = False
            target_datetime = None
            
            if user_query: # æ³¨æ„ï¼šé€™è£¡ä¾ç„¶å‚³å…¥å®Œæ•´çš„ user_query çµ¦ AIï¼Œè®“ AI çŸ¥é“å®Œæ•´æƒ…å¢ƒ
                ai_intent = self.intent_agent.analyze_user_intent(user_query)
                logger.info(f"ğŸ§  AI æ„åœ–åˆ†æçµæœ: {ai_intent}")
                
                if ai_intent and "time_filter" in ai_intent:
                    tf = ai_intent["time_filter"]
                    filter_open_now = tf.get("filter_open_now", filter_open_now)
                    target_datetime = tf.get("target_iso_datetime", target_datetime)
                    logger.info(f"ğŸ•’ AI åˆ¤å®šæ™‚é–“æ¢ä»¶ -> ç¾åœ¨ç‡Ÿæ¥­: {filter_open_now}, æŒ‡å®šæ™‚é–“: {target_datetime}")

            # === 3. æ±ºå®šæª¢æŸ¥æ™‚é–“é» ===
            check_time = None
            if target_datetime:
            # æƒ…æ³ Aï¼šæœ‰æ˜ç¢ºæŒ‡å®šæœªä¾†æ™‚é–“
                try: 
                    check_time = datetime.fromisoformat(target_datetime)
                    logger.info(f"ğŸ•’ [æ™‚é–“éæ¿¾] ä¾ç…§ AI æŒ‡å®šæ™‚é–“: {check_time.strftime('%Y-%m-%d %H:%M')}")
                except: 
                    check_time = datetime.now()
            else:
            # æƒ…æ³ Bï¼šæ²’æœ‰æŒ‡å®šæ™‚é–“ï¼Œæˆ–æ˜¯ AI æ–·ç·šå›å‚³ {}ã€‚ä¸€å¾‹å¼·åˆ¶è¨­å®šç‚ºã€Œç¾åœ¨ã€ï¼
                check_time = datetime.now()
                filter_open_now = True  # é †æ‰‹æŠŠç‹€æ…‹åˆ‡ç‚º Trueï¼Œç¶­æŒé‚è¼¯ä¸€è‡´æ€§
                logger.info(f"ğŸ•’ [æ™‚é–“éæ¿¾] æœªæŒ‡å®šæ™‚é–“ï¼Œé è¨­å°‹æ‰¾ã€Œç¾åœ¨ã€æœ‰ç‡Ÿæ¥­çš„åº—å®¶: {check_time.strftime('%Y-%m-%d %H:%M')}")
            
            # å®šç¾©å…§éƒ¨éæ¿¾å‡½å¼
            def filter_by_opening_hours(candidates):
                if not check_time: return candidates
                open_cafes = []
                for cafe in candidates:
                    opening_hours = cafe.get('opening_hours', {})
                    if not opening_hours: continue
                    if opening_hours.get('is_24_hours'):
                        open_cafes.append(cafe)
                        continue
                    if is_google_period_open(opening_hours.get('periods', []), check_time):
                        open_cafes.append(cafe)
                return open_cafes

            # === 4. å–å¾—é»‘åå–® ===
            blacklist_ids = []
            if user_id:
                logs = list(db['interaction_logs'].find({"user_id": user_id, "action": "NO"}, {"place_id": 1}))
                blacklist_ids = [l['place_id'] for l in logs]
            
            # æŠŠå®ƒåŠ é€²é€™æ¬¡çš„é»‘åå–®è£¡ï¼Œç¢ºä¿å®ƒçµ•å°ä¸æœƒåœ¨ä¸‹ä¸€ç§’åˆè¢«æ¨å‡ºä¾†ï¼
            if rejected_place_id and rejected_place_id not in blacklist_ids:
                blacklist_ids.append(rejected_place_id)

            # æŠŠè² é¢åŸå› åŠ å…¥å‘é‡æœå°‹ (Path A çš„ Prompt Injection)
            if search_query and negative_reason: # æ³¨æ„é€™è£¡ç”¨ search_query
                search_query = f"{search_query}ï¼Œä½†è«‹çµ•å°é¿é–‹ã€Œ{negative_reason}ã€çš„ç‰¹å¾µ"
                logger.info(f"ğŸ›¡ï¸ è§¸ç™¼åŠ‡æœ¬ä¸€ï¼šåŠ å…¥é¿é›·ç‰¹å¾µçš„å‘é‡æœå°‹ -> {search_query}")
            
            # å¦‚æœæ²’æœ‰åŸå› ï¼Œä½†æœ‰æ‹’çµ•çš„åº—å®¶ï¼Œå» DB æŠ“è©²åº—çš„æ¨™ç±¤
            rejected_tags = []
            if rejected_place_id and not negative_reason:
                rejected_cafe = db['cafes'].find_one({"place_id": rejected_place_id}, {"ai_tags": 1})
                if rejected_cafe and 'ai_tags' in rejected_cafe:
                    # ç¢ºä¿æ‹¿åˆ°çš„æ˜¯ listï¼Œé¿å…éŒ¯èª¤
                    if isinstance(rejected_cafe['ai_tags'], list):
                        rejected_tags = [t.get('tag', '') for t in rejected_cafe['ai_tags'] if isinstance(t, dict)]
                logger.info(f"ğŸ›¡ï¸ è§¸ç™¼åŠ‡æœ¬äºŒï¼šæå–æ‹’çµ•åº—å®¶çš„éš±æ€§ç‰¹å¾µ -> {rejected_tags}")

            final_data = []

            # === Path A: å‘é‡æœå°‹ ===
            # ğŸ”¥ [çµ„å“¡æ–°å¢é‚è¼¯] åªæœ‰åœ¨æ¸…æ´—å¾Œçš„ search_query æœ‰å€¼æ™‚æ‰è·‘å‘é‡
            if search_query:
                logger.info(f"ğŸ” [Path A] å•Ÿå‹•å‘é‡æœå°‹: é—œéµå­— '{search_query}'")
                query_vector = self.get_embedding(search_query)
                
                if query_vector:
                    logger.info(f"âœ… [AI èªæ„åˆ†ææˆåŠŸ] å‘é‡ç¶­åº¦: {len(query_vector)}")

                    pipeline_vec = [
                        {"$vectorSearch": {
                            "index": "vector_index", "path": "embedding", "queryVector": query_vector,
                            "numCandidates": 100, "limit": 50
                        }},
                        {"$lookup": {
                            "from": "cafes", "localField": "place_id", "foreignField": "place_id", "as": "cafe_info"
                        }},
                        {"$unwind": "$cafe_info"},
                        {"$project": {
                            "place_id": "$cafe_info.place_id",
                            "final_name": "$cafe_info.final_name",
                            "original_name": "$cafe_info.original_name",
                            "location": "$cafe_info.location",
                            "rating": "$cafe_info.total_ratings",
                            "attributes": "$cafe_info.attributes",
                            "ai_tags": "$cafe_info.ai_tags",
                            "tags": "$cafe_info.tags",
                            "vector_score": { "$meta": "vectorSearchScore" },
                            "matched_review": "$content",
                            "opening_hours": "$cafe_info.opening_hours",
                            "contact": "$cafe_info.contact"
                        }}
                    ]
                    
                    if blacklist_ids:
                        pipeline_vec.append({"$match": {"place_id": {"$nin": blacklist_ids}}})

                    raw_results = list(db['reviews'].aggregate(pipeline_vec))
                    logger.info(f"ğŸ“¦ [æ¼æ–—ç›£æ§] å‘é‡æœå°‹ & lookup å®Œï¼Œåˆå§‹ç­†æ•¸: {len(raw_results)}")
                    
                    raw_results = filter_by_opening_hours(raw_results)
                    logger.info(f"â³ [æ¼æ–—ç›£æ§] æ™‚é–“éæ¿¾å¾Œï¼Œå‰©é¤˜ç­†æ•¸: {len(raw_results)}")

# ////////////////////////////////
# notionåˆ†éš”
# ////////////////////////////////

                    filtered_results = []
                    for item in raw_results:
                        if not item.get('location') or 'coordinates' not in item['location']: continue
                        c_loc = (item['location']['coordinates'][1], item['location']['coordinates'][0])
                        dist_meters = geodesic(user_loc, c_loc).meters
                        
                        logger.info(f"ğŸ“ åº—å: {item.get('final_name')} | è·é›¢: {int(dist_meters)}m")

                        if dist_meters <= 3000:
                            item['dist_meters'] = int(dist_meters)
                            hours_until_close = 3.0
                            clicks, keeps, dislikes = 0, 0, 0
                            has_disliked_features = False
                            if rejected_tags:
                                item_tags = [t['tag'] for t in item.get('ai_tags', [])]
                                # å¦‚æœé€™å®¶åº—çš„æ¨™ç±¤è·Ÿè¢«æ‹’çµ•çš„åº—æœ‰äº¤é›†ï¼Œè§¸ç™¼æ‰“ 8 æŠ˜æ‡²ç½°
                                if set(rejected_tags) & set(item_tags):
                                    has_disliked_features = True
                            # ğŸŒŸ å‘¼å«ä½ çš„ 8 ç¶­åº¦å¤§è…¦ï¼
                            item['search_score'] = calculate_comprehensive_score(
                                vec_score=item.get('vector_score', 0.8),
                                rating=item.get('rating', 0) or 0,
                                total_reviews=item.get('total_ratings', 0),
                                dist_meters=dist_meters,
                                dist_to_nearest_mrt=500.0, # (å…ˆçµ¦é è¨­å€¼ï¼Œå¾ŒçºŒéšæ®µå››å†è£œé½Š DB æ¬„ä½)
                                hours_until_close=hours_until_close,
                                clicks=clicks, keeps=keeps, dislikes=dislikes,
                                is_new_user=False, # (å¯é€é user_service åˆ¤æ–·)
                                has_disliked_features=has_disliked_features
                            )
                            filtered_results.append(item)
                        
                        else:
                            logger.info(f"   âŒ å¤ªé è¢«ç§»é™¤ (>3000m)")
                    
                    logger.info(f"ğŸ“ [æ¼æ–—ç›£æ§] è·é›¢ (3000m) éæ¿¾å¾Œï¼Œæœ€çµ‚ç­†æ•¸: {len(filtered_results)}")
                    filtered_results.sort(key=lambda x: x['search_score'], reverse=True)
                    final_data = filtered_results[:10]

                # ğŸ”¥ [çµ„å“¡æ–°å¢] å®‰å…¨ç¶²ï¼šå¦‚æœ Path A æ‘ƒé¾œï¼Œå¼·åˆ¶é™ç´šè·‘ Path B
                if not final_data:
                    logger.info("âš ï¸ Path A æŸ¥ç„¡çµæœï¼Œè‡ªå‹•é™ç´šç‚º Path B (é¿å…ç©ºç™½)")
                    search_query = None 

            # === Path B: Tag/Geo æœå°‹ ===
            # ğŸ”¥ [é‚è¼¯èåˆ] çµåˆçµ„å“¡çš„ search_query åˆ¤æ–· èˆ‡ æˆ‘å€‘çš„é«˜ç´š Pipeline
            if not final_data and (cafe_tag or not search_query):
                target_tag = cafe_tag if cafe_tag else ""
                logger.info(f"ğŸŒ [Path B] å•Ÿå‹•åœ°ç†/æ¨™ç±¤æœå°‹ (Tag: {target_tag if target_tag else 'ç„¡'})")
                
                pipeline = [
                    {"$geoNear": {
                        "near": {"type": "Point", "coordinates": [current_search_lng, current_search_lat]},
                        "distanceField": "dist_meters", "maxDistance": 3000, "spherical": True
                    }}
                ]
                
                # ğŸ›¡ï¸ [ç¶­æŒåŸç‰ˆ] ä¿æŒé»‘åå–®éæ¿¾
                if blacklist_ids:
                    pipeline.append({"$match": {"place_id": {"$nin": blacklist_ids}}})
                
                if target_tag:
                    pipeline.append({"$match": {"$or": [
                                        {"original_name": {"$regex": target_tag, "$options": "i"}},
                                        {"tags": {"$regex": target_tag, "$options": "i"}}  # åªç•™æœ€æ–°çš„ç¥ç´šæ¨™ç±¤é™£åˆ—
                                    ]}})

                # ğŸ‘‘ [ç¶­æŒåŸç‰ˆ] æ”¾æ£„çµ„å“¡ç°¡é™‹çš„ sortï¼Œå …æŒä½¿ç”¨é€™å¥—ç¥ç´šå‹•æ…‹è·é›¢è¡°æ¸›ç®—åˆ†å…¬å¼ï¼
                pipeline.append({"$addFields": {
                    "search_score": {
                        "$divide": [{"$ifNull": ["$rating", 0]}, {"$add": [{"$divide": ["$dist_meters", 100]}, 1]}]
                    }
                }})
                pipeline.append({"$sort": {"search_score": -1}})
                pipeline.append({"$limit": 50}) # ç¶­æŒ 50 å†å»éæ¿¾æ™‚é–“

                path_b_results = list(db['cafes'].aggregate(pipeline))
                open_results = filter_by_opening_hours(path_b_results)
                final_data = open_results[:10]

            # === ğŸ”¥ [æ–°å¢] æ¨™ç±¤å‹•æ…‹æ’åºèˆ‡è¦–è¦ºåŒ–è™•ç† ===
            def process_display_tags(raw_tags, query_text, btn_tag):
                if not isinstance(raw_tags, list): return []
                
                # 1. å®šç¾©é»‘åå–® (çµ•å°ä¸è¦é¡¯ç¤ºåœ¨ Flex Message ä¸Š)
                negative_tags = {"æº«åº¦å†·", "æ‚¶ç†±", "æœå‹™è¦ªåˆ‡", "æœå‹™ä¸ä½³", "æœå‹™æ•ˆç‡ä¸ä½³", "åœè»Šå›°é›£"}
                
                # 2. å®šç¾©é«˜åƒ¹å€¼ç™½åå–® (è‡ªå¸¶æµé‡çš„æ˜æ˜Ÿæ¨™ç±¤)
                high_value_tags = {"å·¥ä½œå‹å–„", "ä¸é™æ™‚", "æ’åº§", "Wi-Fi", "æ·±å¤œ", "åº—è²“", "åº—ç‹—", "è€å®…", "ç”œé»", "æ‰‹æ²–ç²¾å“"}
                
                # 3. éæ¿¾é»‘åå–®
                filtered_tags = [t for t in raw_tags if t not in negative_tags]
                
                # 4. è¨ˆç®—æ¬Šé‡
                def get_weight(tag):
                    weight = 0
                    # çµ•å°å„ªå…ˆ (ä½¿ç”¨è€…å‘½ä¸­)
                    if query_text and tag in query_text: weight += 10
                    if btn_tag and tag == btn_tag: weight += 10
                    # æ¬¡è¦å„ªå…ˆ (é«˜åƒ¹å€¼ç‰¹å¾µ)
                    if tag in high_value_tags: weight += 5
                    return weight
                
                # 5. æ’åºä¸¦å–å‰ 3 å€‹
                sorted_tags = sorted(filtered_tags, key=get_weight, reverse=True)[:3]
                
                # 6. ä½¿ç”¨å¼•å…¥çš„ TAG_EMOJI_MAP è½‰æˆ Emoji æ ¼å¼ (è‹¥å­—å…¸æ²’æœ‰è©² tagï¼Œå‰‡ä¿æŒåŸæ–‡å­—)
                return [TAG_EMOJI_MAP.get(t, t) for t in sorted_tags]
            
            # === æ ¼å¼åŒ–è¼¸å‡º ===
            formatted_response = []
            for r in final_data:
                # ğŸ¯ æŒ–æ˜ MongoDB ä¸­çš„ ratings Object
                db_ratings = r.get("ratings", {})
                rating_val = db_ratings.get("rating", 0.0)
                review_count = db_ratings.get("review_amount", 0)

                formatted_response.append({
                    "place_id": r.get("place_id", str(r.get("_id"))),
                    "final_name": r.get("final_name", "æœªçŸ¥åº—å®¶"),
                    "original_name": r.get("original_name"),
                    "dist_meters": int(r.get("dist_meters", 0)),
                    "rating": rating_val,
                    "display_tags": process_display_tags(r.get("tags", []), search_query, cafe_tag),
                    "attributes": r.get("attributes", {}),
                    "total_ratings": review_count,
                    "match_reason": r.get("matched_review", "ç¬¦åˆæ¢ä»¶"),
                    # ğŸ”¥ [çµ„å“¡æ–°å¢] å°‡ opening_hours å‚³éçµ¦å‰ç«¯ UI åˆ¤æ–·ç¶ è‰²ç‡Ÿæ¥­ä¸­
                    "opening_hours": r.get("opening_hours", {}),
                    "contact": r.get("contact", {}) 
                })
            return {
                "data": formatted_response,
                "center_lat": current_search_lat,
                "center_lng": current_search_lng
            }

        except Exception as e:
            # ğŸ›¡ï¸ [ç¶­æŒåŸç‰ˆ] å®Œæ•´éŒ¯èª¤è»Œè·¡
            logger.error(f"âŒ æ¨è–¦æœå‹™åŸ·è¡Œå¤±æ•—: {e}")
            logger.error(traceback.format_exc()) 
            return {"data": []}