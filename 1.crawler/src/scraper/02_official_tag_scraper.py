import sys
import os
import time
import random
import io
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from google.cloud import storage
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException

# --- 1. é›²ç«¯å·¥å…·å‡½æ•¸ ---
def get_gcs_client():
    return storage.Client()

def load_csv_from_gcs(bucket_name, blob_name):
    """å¾ GCS è®€å– CSV è½‰ç‚º DataFrame """
    client = get_gcs_client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)
    
    if not blob.exists():
        print(f"âš ï¸ GCS æª”æ¡ˆä¸å­˜åœ¨: gs://{bucket_name}/{blob_name}")
        return None
        
    content = blob.download_as_string()
    return pd.read_csv(io.BytesIO(content))

def upload_df_to_gcs(df, bucket_name, blob_name):
    """å°‡ DataFrame ä¸Šå‚³å› GCS """
    client = get_gcs_client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)
    
    csv_buffer = io.StringIO()
    df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
    blob.upload_from_string(csv_buffer.getvalue(), content_type='text/csv')
    print(f"âœ… å·²å„²å­˜è‡³: gs://{bucket_name}/{blob_name}")

# --- 2. çµæ§‹åŒ–æ¸…æ´—å‡½æ•¸ ---
def clean_google_tags_final(raw_content):
    if not raw_content: return "", ""

    lines = [l.strip() for l in raw_content.split('\n') if l.strip()]
    unique_lines = []
    [unique_lines.append(x) for x in lines if x not in unique_lines]

    formatted_sections = []
    payment_methods = []
    
    for section in unique_lines:
        if "î€³" in section or "[ç„¡]" in section:
            continue

        if 'î—Š' in section:
            parts = section.split('î—Š')
            category = parts[0].strip()
            items_list = [p.strip() for p in parts[1:] if p.strip()]
            
            items_str = " | ".join(items_list)
            formatted_sections.append(f"{category}ï¼š{items_str}")
            
            if "ä»˜æ¬¾" in category:
                payment_methods.extend(items_list)

    full_tags_text = " || ".join(formatted_sections)
    payment_options_str = ",".join(payment_methods) if payment_methods else ""
    
    return full_tags_text, payment_options_str

# --- 3. æ ¸å¿ƒåŸ·è¡Œé‚è¼¯ ---
if __name__ == "__main__":
    # 1. ç’°å¢ƒè®Šæ•¸è¨­å®š
    BUCKET_NAME = os.getenv("GCS_BUCKET_NAME", "tjr104-cafe-datalake")
    REGION = os.getenv("SCAN_REGION", "A-2")
    ENV_LIMIT = os.getenv("SCAN_LIMIT")
    SCAN_LIMIT = int(ENV_LIMIT) if (ENV_LIMIT and ENV_LIMIT.isdigit()) else None

    if not BUCKET_NAME:
        print("âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸ GCS_BUCKET_NAME")
        sys.exit(1)

    BASE_CSV_PATH = "raw/store/base.csv"
    TAGS_TOTAL_PATH = "raw/tag/tags_total.csv"

    print(f"\n" + "="*50)
    print(f"ğŸš€ [Tag Scraper] ç©©å®šç‰ˆå•Ÿå‹•")
    print(f"ğŸ“ ç›®æ¨™å€åŸŸ: {REGION} | é™åˆ¶ç­†æ•¸: {SCAN_LIMIT if SCAN_LIMIT else 'ç„¡'}")
    print(f"="*50)

    # è®€å–åå–®
    full_df = load_csv_from_gcs(BUCKET_NAME, BASE_CSV_PATH)
    if full_df is None or full_df.empty:
        print("âŒ æ‰¾ä¸åˆ°åº—å®¶ç¸½è¡¨ (base.csv)")
        sys.exit(1)

    df_existing_tags = load_csv_from_gcs(BUCKET_NAME, TAGS_TOTAL_PATH)
    
    if df_existing_tags is not None and not df_existing_tags.empty:
        done_ids = set(df_existing_tags['place_id'].unique())
        df_to_process = full_df[~full_df['place_id'].isin(done_ids)]
    else:
        df_to_process = full_df
        df_existing_tags = pd.DataFrame()

    if SCAN_LIMIT:
        df_to_process = df_to_process.head(SCAN_LIMIT)

    if df_to_process.empty:
        print("âœ… æ‰€æœ‰åº—å®¶çš†å·²çˆ¬å–å®Œç•¢ã€‚")
        sys.exit(0)

    # --- åˆå§‹åŒ– Selenium ---
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage") # è§£æ±º Tab Crashed é—œéµ 
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--lang=zh-TW")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    wait = WebDriverWait(driver, 15)
    
    batch_size = 3  # è¨­å®šæ¯ 3 ç­†ç‚ºä¸€å€‹æ‰¹æ¬¡
    new_tag_records = []
    payment_patch = {}

    try:
        for i, (index, row) in enumerate(df_to_process.iterrows(), 1):
            place_id = row.get('place_id')
            name = row.get('name')
            address = row.get('formatted_address', '')
            
            if (i - 1) % batch_size == 0:
                if 'driver' in locals(): driver.quit() # å¦‚æœå·²æœ‰ driver å‰‡å…ˆé—œé–‰
                print(f"ğŸ”„ å•Ÿå‹•å…¨æ–°ç€è¦½å™¨å¯¦ä¾‹ (è™•ç†ç¬¬ {i} ç­†èµ·)...")
                driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
                wait = WebDriverWait(driver, 15)

            beautiful_text, payment_options, raw_content = "", "", ""
            query = f"{name} {str(address)[:10]}"
            print(f"ğŸ” [{index+1}/{len(df_to_process)}] æœå°‹: {name}")

            try:
                # A. å‰å¾€ä¸»é  (ä½¿ç”¨æ¨™æº– Google Maps ç¶²å€æé«˜ç©©å®šæ€§)
                driver.get("https://www.google.com.tw/maps?hl=zh-TW")
                
                # B. è™•ç† Cookie åŒæ„å½ˆçª—
                try:
                    consent_btn = WebDriverWait(driver, 5).until(
                        EC.element_to_be_clickable((By.CSS_SELECTOR, "button[aria-label*='å…¨éƒ¨æ¥å—'], button[aria-label*='Accept all']"))
                    )
                    consent_btn.click()
                    time.sleep(1)
                except:
                    pass

                # C. é¡¯å¼ç­‰å¾…æœå°‹æ¡†å‡ºç¾
                search_box = driver.find_element(By.NAME, "q")
                search_box.clear()
                search_box.send_keys(query)
                search_box.send_keys(Keys.ENTER)
                time.sleep(random.uniform(2, 4))

                # D. è™•ç†åˆ—è¡¨æˆ–ç›´æ¥é€²å…¥
                list_items = driver.find_elements(By.CLASS_NAME, "hfpxzc")
                if list_items:
                    list_items[0].click()
                    time.sleep(2)

                # E. é»æ“Šã€Œé—œæ–¼ã€åˆ†é  (å¢åŠ ç­‰å¾…)
                try:
                    about_btn = wait.until(EC.element_to_be_clickable((By.XPATH, "//button[contains(@aria-label, 'é—œæ–¼') or contains(@aria-label, 'ç°¡ä»‹') or .//div[text()='é—œæ–¼']]")))
                    driver.execute_script("arguments[0].click();", about_btn)
                    time.sleep(2)
                except:
                    print(f" â„¹ï¸  {name} ç„¡æ³•é»æ“Šã€Œé—œæ–¼ã€åˆ†é ")

                # F. è§£ææ¨™ç±¤
                soup = BeautifulSoup(driver.page_source, "html.parser")
                info_blocks = soup.select('div[role="region"].m6QErb div.iP2t7d')
                for b in info_blocks:
                    raw_content += b.get_text(separator="\n") + "\n"

                if raw_content.strip():
                    beautiful_text, payment_options = clean_google_tags_final(raw_content)

                if payment_options:
                    payment_patch[place_id] = payment_options

                if beautiful_text:
                    for section in beautiful_text.split(" || "):
                        new_tag_records.append({
                            'name': name, 'place_id': place_id, 'Tag': section,
                            'data_source': 'google_about_tab', 'crawled_at': time.strftime('%Y-%m-%d %H:%M:%S')
                        })
                    print(f" Â  Â âœ… æ¨™ç±¤æ¡é›†æˆåŠŸ")

            except (TimeoutException, WebDriverException) as e:
                page_title = driver.title
                print(f" Â  Â âŒ {name} éç¨‹å‡ºéŒ¯ (è·³é): {type(e).__name__}")
                print(f" Â  Â â„¹ï¸ ç•¶æ™‚ç¶²é æ¨™é¡Œç‚º: {page_title} | ç¶²å€: {driver.current_url}")

                continue # è·³éé€™é–“ï¼Œç¹¼çºŒä¸‹ä¸€é–“
            
            time.sleep(random.uniform(1, 2))

            # --- ğŸŒŸ é—œéµé»ï¼šæ¯ 3 ç­†åŸ·è¡Œä¸€æ¬¡ã€Œä¸­é€”å­˜æª”ã€ ---
            if i % batch_size == 0 or i == len(df_to_process):
                if new_tag_records:
                    print(f"ğŸ’¾ é”åˆ° {batch_size} ç­†ï¼ŒåŸ·è¡Œä¸­é€”å­˜æª”è‡³ GCS...")
                    
                    # é‡æ–°è®€å–æœ€æ–°çš„ç¸½è¡¨ (é¿å…å¤šå€‹ Job åŒæ™‚å¯«å…¥è¡çªï¼Œé›–ç„¶ Job é€šå¸¸æ˜¯å–®ä¸€çš„)
                    df_latest_existing = load_csv_from_gcs(BUCKET_NAME, TAGS_TOTAL_PATH)
                    df_new_batch = pd.DataFrame(new_tag_records)
                    
                    # åˆä½µä¸¦å»é‡
                    df_updated_tags = pd.concat([df_latest_existing, df_new_batch], ignore_index=True)
                    df_updated_tags = df_updated_tags.drop_duplicates(subset=['place_id', 'Tag'])
                    
                    # å­˜å› GCS
                    upload_df_to_gcs(df_updated_tags, BUCKET_NAME, TAGS_TOTAL_PATH)
                    
                    # å­˜å®Œå¾Œæ¸…ç©ºæš«å­˜å®¹å™¨ï¼Œé¿å…ä¸‹æ¬¡é‡è¤‡å­˜å…¥
                    new_tag_records = []
                    print(f"âœ… ä¸­é€”å­˜æª”å®Œæˆï¼Œå·²é‡‹æ”¾æš«å­˜æ¸…å–®ã€‚")

    finally:
        # ğŸŒŸ é‡‹æ”¾è³‡æºèˆ‡è¨˜æ†¶é«”
        if 'driver' in locals():
            driver.quit()
            print("ğŸ§¹ ä»»å‹™çµæŸï¼Œç€è¦½å™¨å·²é—œé–‰ã€‚")

    # --- å„²å­˜è³‡æ–™ ---
    if new_tag_records:
        df_new_tags = pd.DataFrame(new_tag_records)
        df_final_tags = pd.concat([df_existing_tags, df_new_tags], ignore_index=True).drop_duplicates(subset=['place_id', 'Tag'])
        upload_df_to_gcs(df_final_tags, BUCKET_NAME, TAGS_TOTAL_PATH)
        
        if payment_patch:
            full_df['payment_options'] = full_df['place_id'].map(payment_patch).fillna(full_df.get('payment_options', ''))
            upload_df_to_gcs(full_df, BUCKET_NAME, BASE_CSV_PATH)

    print(f"ğŸ‰ å€åŸŸ {REGION} ä»»å‹™å®Œæˆï¼")