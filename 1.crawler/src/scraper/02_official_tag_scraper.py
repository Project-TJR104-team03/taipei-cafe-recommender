import os
import time
import random
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# --- 1. åˆå§‹åŒ–ç’°å¢ƒè®Šæ•¸ ---
root_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
load_dotenv(dotenv_path=os.path.join(root_path, ".env"))

# --- 2. çµæ§‹åŒ–æ¸…æ´—å‡½æ•¸ (ç§»é™¤ç¬¦è™Ÿã€éæ¿¾æ–œç·šã€æŠ“æ”¯ä»˜æ–¹å¼) ---
def clean_google_tags_final(raw_content):
    if not raw_content: return "", ""

    lines = [l.strip() for l in raw_content.split('\n') if l.strip()]
    unique_lines = []
    [unique_lines.append(x) for x in lines if x not in unique_lines]

    formatted_sections = []
    payment_methods = []
    
    for section in unique_lines:
        # éæ¿¾ï¼šæœ‰æ–œç·š (î€³) æˆ– [ç„¡] ä»£è¡¨æ²’æœ‰æä¾›ï¼Œç›´æ¥è·³éä¸æŠ“
        if "î€³" in section or "[ç„¡]" in section:
            continue

        if 'î—Š' in section:
            parts = section.split('î—Š')
            category = parts[0].strip()
            # ç§»é™¤âœ”ï¼šåªæŠ“å–æ–‡å­—é …ç›®
            items_list = [p.strip() for p in parts[1:] if p.strip()]
            
            # æ ¼å¼ï¼šé¡åˆ¥ï¼šé …ç›®1 | é …ç›®2
            items_str = " | ".join(items_list)
            formatted_sections.append(f"{category}ï¼š{items_str}")
            
            # æå–æ”¯ä»˜æ–¹å¼ä¾›å¾ŒçºŒå›å¡«
            if "ä»˜æ¬¾" in category:
                payment_methods.extend(items_list)

    full_tags_text = " || ".join(formatted_sections)
    # æ”¯ä»˜æ–¹å¼åˆä½µç‚ºé€—è™Ÿå­—ä¸²
    payment_options_str = ",".join(payment_methods) if payment_methods else ""
    
    return full_tags_text, payment_options_str

# --- 3. è¨­å®šå€ ---
REGION = os.getenv("SCAN_REGION", "A-2")
STATIC_TABLE = f"data/raw/Store/{REGION}_base.csv"
TAG_COLUMN_FILE = f"data/raw/Tag_column/{REGION}_tags.csv"

HEADLESS = os.getenv("HEADLESS", "false").lower() == "true"
ENV_LIMIT = os.getenv("SCAN_LIMIT")
SCAN_LIMIT = int(ENV_LIMIT) if (ENV_LIMIT and ENV_LIMIT.isdigit()) else None

# --- 4. åŸ·è¡Œé‚è¼¯ ---
if not os.path.exists(STATIC_TABLE):
    print(f" æ‰¾ä¸åˆ°éœæ…‹ Table æª”æ¡ˆ: {STATIC_TABLE}")
else:
    full_df = pd.read_csv(STATIC_TABLE)
    payment_patch = {}
    df_to_process = full_df.head(SCAN_LIMIT) if SCAN_LIMIT else full_df

    options = webdriver.ChromeOptions()
    if HEADLESS:
        options.add_argument("--headless")
    
    # ğŸŒŸ é—œéµä¿®æ­£ï¼šå¼·åˆ¶è¨­å®šç‚ºçª„é•·è¦–çª—ï¼Œé¿å… Google è·³å‡ºåœ°åœ–å´é‚Šæ¬„
    options.add_argument("--window-size=900,1000")
    options.add_argument("--disable-blink-features=AutomationControlled")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    try:
        for index, row in df_to_process.iterrows():
            query = f"{row['name']} {str(row['formatted_address'])[:10]}"
            print(f" è™•ç†ä¸­ [{index+1}/{len(df_to_process)}]: {row['name']}")

            driver.get("https://www.google.com/maps")
            time.sleep(1.5)

            try:
                search_box = driver.find_element(By.NAME, "q")
                search_box.clear()
                search_box.send_keys(query + Keys.ENTER)
                time.sleep(5)

                # åˆ—è¡¨é»æ“Šè£œæ•‘æ©Ÿåˆ¶
                list_items = driver.find_elements(By.CLASS_NAME, "hfpxzc")
                if list_items:
                    list_items[0].click()
                    time.sleep(4)

                # é»æ“Šã€Œé—œæ–¼ã€åˆ†é 
                try:
                    about_btn = driver.find_element(By.XPATH, "//button[contains(@aria-label, 'é—œæ–¼') or contains(@aria-label, 'ç°¡ä»‹')]")
                    about_btn.click()
                    time.sleep(2)
                except:
                    pass

                soup = BeautifulSoup(driver.page_source, "html.parser")
                raw_content = ""
                # æ¡ç”¨æœ€ç©©å®šçš„ç°¡ä»‹å€å¡Šé¸æ“‡å™¨
                info_blocks = soup.select('div[role="region"].m6QErb div.iP2t7d')
                for b in info_blocks:
                    raw_content += b.text + "\n"

                # è§£ææ¨™ç±¤èˆ‡æ”¯ä»˜æ–¹å¼
                beautiful_text, payment_options = clean_google_tags_final(raw_content)

                # æš«å­˜çµæœ
                if payment_options:
                    payment_patch[row['place_id']] = payment_options
                    print(f"    æ‰¾åˆ°æ”¯ä»˜æ–¹å¼: {payment_options}")

                # å­˜å…¥ Tag_column
                if beautiful_text:
                    tag_records = []
                    for section in beautiful_text.split(" || "):
                        tag_records.append({
                            'name': row['name'],
                            'place_id': row['place_id'],
                            'Tag': section,
                            'Tag_id': "PENDING",
                            'data_source': 'googleç°¡ä»‹æ¨™ç±¤'
                        })
                    os.makedirs(os.path.dirname(TAG_COLUMN_FILE), exist_ok=True)
                    pd.DataFrame(tag_records).to_csv(TAG_COLUMN_FILE, mode='a', index=False, header=not os.path.exists(TAG_COLUMN_FILE), encoding='utf-8-sig')

            except Exception as e:
                print(f"    {row['name']} é­é‡éŒ¯èª¤ï¼Œè·³éã€‚")

            time.sleep(random.uniform(1, 2))

        # --- 5. æœ€çµ‚å›å¡« ---
        if payment_patch:
            print(f"\næ­£åœ¨å°‡æ”¯ä»˜æ–¹å¼å›å¡«è‡³ {STATIC_TABLE}...")
            full_df['payment_options'] = full_df['place_id'].map(payment_patch).fillna(full_df['payment_options'])
            full_df.to_csv(STATIC_TABLE, index=False, encoding='utf-8-sig')
            print(f"éœæ…‹ Table å›å¡«æ›´æ–°æˆåŠŸï¼")

    finally:
        driver.quit()
        print(f"ä»»å‹™åœ“æ»¿çµæŸï¼")