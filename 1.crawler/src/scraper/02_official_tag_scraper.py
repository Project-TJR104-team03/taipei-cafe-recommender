import sys
import os
import time
import random
import io
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from google.cloud import storage
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException

# --- 1. é›²ç«¯å·¥å…·å‡½æ•¸ ---
def get_gcs_client():
    return storage.Client()

def load_csv_from_gcs(bucket_name, blob_name):
    """å¾ GCS è®€å– CSV"""
    client = get_gcs_client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)
    if not blob.exists():
        return None
    content = blob.download_as_string()
    return pd.read_csv(io.BytesIO(content))

def upload_df_to_gcs(df, bucket_name, blob_name):
    """ä¸Šå‚³ DataFrame åˆ° GCS"""
    client = get_gcs_client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)
    csv_buffer = io.StringIO()
    df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
    blob.upload_from_string(csv_buffer.getvalue(), content_type='text/csv')
    print(f" å·²å„²å­˜è‡³: gs://{bucket_name}/{blob_name}")

# --- 2. æ¨™ç±¤æ¸…æ´—å‡½å¼ ---
def clean_google_tags_final(raw_content):
    if not raw_content: return "", ""
    lines = [l.strip() for l in raw_content.split('\n') if l.strip()]
    unique_lines = []
    [unique_lines.append(x) for x in lines if x not in unique_lines]

    formatted_sections = []
    payment_methods = []
    
    for section in unique_lines:
        if "î€³" in section or "[ç„¡]" in section: continue
        if 'î—Š' in section:
            parts = section.split('î—Š')
            category = parts[0].strip()
            items_list = [p.strip() for p in parts[1:] if p.strip()]
            items_str = " | ".join(items_list)
            formatted_sections.append(f"{category}ï¼š{items_str}")
            if "ä»˜æ¬¾" in category:
                payment_methods.extend(items_list)

    full_tags_text = " || ".join(formatted_sections)
    payment_options_str = ",".join(payment_methods) if payment_methods else ""
    return full_tags_text, payment_options_str

# --- 3. æ ¸å¿ƒåŸ·è¡Œé‚è¼¯ ---
if __name__ == "__main__":
    BUCKET_NAME = os.getenv("GCS_BUCKET_NAME", "tjr104-cafe-datalake")
    REGION = os.getenv("SCAN_REGION", "A-2")
    ENV_LIMIT = os.getenv("SCAN_LIMIT")
    SCAN_LIMIT = int(ENV_LIMIT) if (ENV_LIMIT and ENV_LIMIT.isdigit()) else None

    if not BUCKET_NAME:
        print(" éŒ¯èª¤: æ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸ GCS_BUCKET_NAME")
        sys.exit(1)

    BASE_CSV_PATH = "raw/store/base.csv"
    # æ¶æ§‹å¸«å»ºè­°ï¼šå°‡å®˜æ–¹æ¨™ç±¤ç¨ç«‹å­˜æ”¾ï¼Œé¿å…èˆ‡è©•è«–æ¨™ç±¤æ··æ·†ï¼Œæˆ–è€…ä¾æ“šä½ çš„éœ€æ±‚æ±ºå®šæ˜¯å¦åˆä½µ
    # é€™è£¡ç¤ºç¯„ç¨ç«‹æª”åï¼Œè‹¥ä½ è¦åˆä½µï¼Œè«‹æ”¹ç‚º "raw/tag/tags_total.csv"
    TAGS_TOTAL_PATH = "raw/tag/tags_official.csv"

    print(f"ğŸš€ [02 Cloud Tag & URL Scraper] å•Ÿå‹• | å€åŸŸ: {REGION}")

    full_df = load_csv_from_gcs(BUCKET_NAME, BASE_CSV_PATH)
    if full_df is None or full_df.empty:
        print(" æ‰¾ä¸åˆ° base.csv")
        sys.exit(1)

    # ç°¡å–®éæ¿¾ï¼šåªè·‘é‚„æ²’æœ‰ URL çš„ï¼Œæˆ–è€…æ ¹æ“š SCAN_LIMIT è·‘
    # é€™è£¡å…ˆå‡è¨­ç…§ SCAN_LIMIT è·‘
    df_to_process = full_df.head(SCAN_LIMIT) if SCAN_LIMIT else full_df

    # åˆå§‹åŒ– Selenium (é›²ç«¯é…ç½®)
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=900,1000")
    chrome_options.add_argument("--lang=zh-TW")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    wait = WebDriverWait(driver, 15)
    
    batch_size = 3
    payment_patch = {}
    url_patch = {} #  æ–°å¢ï¼šç¶²å€æ”¶é›†å™¨
    new_tag_records = []

    try:
        for i, (index, row) in enumerate(df_to_process.iterrows(), 1):
            place_id = row.get('place_id')
            name = row.get('name')
            address = row.get('formatted_address', '')
            
            # æ‰¹æ¬¡é‡å•Ÿ (è¨˜æ†¶é«”ç®¡ç†)
            if (i - 1) % batch_size == 0 and i > 1:
                driver.quit()
                driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
                wait = WebDriverWait(driver, 15)

            query = f"{name} {str(address)[:10]}"
            print(f"[{i}/{len(df_to_process)}]  æœå°‹: {name}")

            try:
                driver.get("https://www.google.com.tw/maps")
                time.sleep(1)
                
                # Cookie è™•ç†
                try:
                    btn = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "button[aria-label*='å…¨éƒ¨æ¥å—'], button[aria-label*='Accept all']")))
                    btn.click()
                except: pass

                box = driver.find_element(By.NAME, "q")
                box.clear()
                box.send_keys(query + Keys.ENTER)
                time.sleep(3)

                items = driver.find_elements(By.CLASS_NAME, "hfpxzc")
                if items:
                    items[0].click()
                    time.sleep(2)

                # ğŸŒŸ [é—œéµæ–°å¢]ï¼šæŠ“å–ç•¶å‰ Google Maps ç¶²å€
                current_url = driver.current_url
                url_patch[place_id] = current_url
                print(f"     å–å¾—ç¶²å€")

                # é»æ“Šé—œæ–¼
                try:
                    about_btn = wait.until(EC.element_to_be_clickable((By.XPATH, "//button[contains(@aria-label, 'é—œæ–¼') or contains(@aria-label, 'ç°¡ä»‹')]")))
                    driver.execute_script("arguments[0].click();", about_btn)
                    wait.until(EC.text_to_be_present_in_element((By.CSS_SELECTOR, 'div[role="region"]'), "î—Š"))
                    time.sleep(1)
                except:
                    print(f"     ç„¡æ³•é€²å…¥ç°¡ä»‹é ")

                # è§£æ
                soup = BeautifulSoup(driver.page_source, "html.parser")
                info_blocks = soup.select('div[role="region"].m6QErb div.iP2t7d')
                raw_content = "\n".join([b.text for b in info_blocks])

                beautiful_text, payment_options = clean_google_tags_final(raw_content)

                if payment_options:
                    payment_patch[place_id] = payment_options
                
                if beautiful_text:
                    for section in beautiful_text.split(" || "):
                        new_tag_records.append({
                            'name': name,
                            'place_id': place_id,
                            'Tag': section,
                            'Tag_id': "PENDING",
                            'data_source': 'googleç°¡ä»‹æ¨™ç±¤'
                        })
                    print(f"     æ¨™ç±¤å·²æŠ“å–")

            except Exception as e:
                print(f"     éŒ¯èª¤: {e}")
                continue
            
            time.sleep(random.uniform(1, 2))

            # --- ä¸­é€”å­˜æª” Checkpoint ---
            if i % batch_size == 0:
                print(f" ä¸­é€”å­˜æª”...")
                # 1. å­˜ Tags
                if new_tag_records:
                    df_new_tags = pd.DataFrame(new_tag_records)
                    df_existing_tags = load_csv_from_gcs(BUCKET_NAME, TAGS_TOTAL_PATH)
                    if df_existing_tags is not None:
                        df_updated_tags = pd.concat([df_existing_tags, df_new_tags], ignore_index=True)
                    else:
                        df_updated_tags = df_new_tags
                    
                    df_updated_tags.drop_duplicates(subset=['place_id', 'Tag'], inplace=True)
                    upload_df_to_gcs(df_updated_tags, BUCKET_NAME, TAGS_TOTAL_PATH)
                    new_tag_records = [] # æ¸…ç©ºæš«å­˜

                # 2. å­˜ Base (å›å¡« URL) - é€™è£¡éœ€è¦é‡æ–°è®€å–æœ€æ–°çš„ baseï¼Œä»¥å…è¦†è“‹åˆ¥äººçš„ä¿®æ”¹
                if payment_patch or url_patch:
                    current_base = load_csv_from_gcs(BUCKET_NAME, BASE_CSV_PATH)
                    if current_base is not None:
                        # ä½¿ç”¨ map æ›´æ–°
                        current_base['google_maps_url'] = current_base['place_id'].map(url_patch).fillna(current_base.get('google_maps_url', ''))
                        current_base['payment_options'] = current_base['place_id'].map(payment_patch).fillna(current_base.get('payment_options', ''))
                        upload_df_to_gcs(current_base, BUCKET_NAME, BASE_CSV_PATH)
    finally:
        driver.quit()

    # --- æœ€çµ‚å­˜æª” ---
    print("\n åŸ·è¡Œæœ€çµ‚å­˜æª”...")
    if new_tag_records:
        df_new_tags = pd.DataFrame(new_tag_records)
        df_existing_tags = load_csv_from_gcs(BUCKET_NAME, TAGS_TOTAL_PATH)
        df_final_tags = pd.concat([df_existing_tags, df_new_tags], ignore_index=True) if df_existing_tags is not None else df_new_tags
        df_final_tags.drop_duplicates(subset=['place_id', 'Tag'], inplace=True)
        upload_df_to_gcs(df_final_tags, BUCKET_NAME, TAGS_TOTAL_PATH)

    if payment_patch or url_patch:
        current_base = load_csv_from_gcs(BUCKET_NAME, BASE_CSV_PATH)
        if current_base is not None:
            current_base['google_maps_url'] = current_base['place_id'].map(url_patch).fillna(current_base.get('google_maps_url', ''))
            current_base['payment_options'] = current_base['place_id'].map(payment_patch).fillna(current_base.get('payment_options', ''))
            upload_df_to_gcs(current_base, BUCKET_NAME, BASE_CSV_PATH)

    print(" 02 ä»»å‹™çµæŸï¼")