import sys
import os
import time
import random
import io
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from google.cloud import storage
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# --- 1. é›²ç«¯å·¥å…·å‡½æ•¸ ---
def get_gcs_client():
    return storage.Client()

def load_csv_from_gcs(bucket_name, blob_name):
    """å¾ GCS è®€å– CSV è½‰ç‚º DataFrame"""
    client = get_gcs_client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)
    
    if not blob.exists():
        print(f"âš ï¸ GCS æª”æ¡ˆä¸å­˜åœ¨: gs://{bucket_name}/{blob_name}")
        return None
        
    content = blob.download_as_string()
    return pd.read_csv(io.BytesIO(content))

def upload_df_to_gcs(df, bucket_name, blob_name):
    """å°‡ DataFrame ä¸Šå‚³å› GCS"""
    client = get_gcs_client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)
    
    csv_buffer = io.StringIO()
    df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
    blob.upload_from_string(csv_buffer.getvalue(), content_type='text/csv')
    print(f"âœ… å·²å„²å­˜è‡³: gs://{bucket_name}/{blob_name}")

# --- 2. çµæ§‹åŒ–æ¸…æ´—å‡½æ•¸ (ä¿ç•™åŸæœ¬é‚è¼¯) ---
def clean_google_tags_final(raw_content):
    if not raw_content: return "", ""

    lines = [l.strip() for l in raw_content.split('\n') if l.strip()]
    unique_lines = []
    [unique_lines.append(x) for x in lines if x not in unique_lines]

    formatted_sections = []
    payment_methods = []
    
    for section in unique_lines:
        # éæ¿¾ç‰¹æ®Šç¬¦è™Ÿ
        if "î€³" in section or "[ç„¡]" in section:
            continue

        if 'î—Š' in section:
            parts = section.split('î—Š')
            category = parts[0].strip()
            items_list = [p.strip() for p in parts[1:] if p.strip()]
            
            items_str = " | ".join(items_list)
            formatted_sections.append(f"{category}ï¼š{items_str}")
            
            if "ä»˜æ¬¾" in category:
                payment_methods.extend(items_list)

    full_tags_text = " || ".join(formatted_sections)
    payment_options_str = ",".join(payment_methods) if payment_methods else ""
    
    return full_tags_text, payment_options_str

# --- 3. æ ¸å¿ƒåŸ·è¡Œé‚è¼¯ ---
if __name__ == "__main__":
    # 1. ç’°å¢ƒè®Šæ•¸è¨­å®š
    BUCKET_NAME = os.getenv("GCS_BUCKET_NAME", "tjr104-cafe-datalake")
    REGION = os.getenv("SCAN_REGION", "A-2")
    ENV_LIMIT = os.getenv("SCAN_LIMIT")
    SCAN_LIMIT = int(ENV_LIMIT) if (ENV_LIMIT and ENV_LIMIT.isdigit()) else None

    # æª¢æŸ¥æ˜¯å¦æ‹¿åˆ°äº†ï¼Œæ²’æ‹¿åˆ°å°±å ±éŒ¯ï¼ˆé é˜²é›²ç«¯æ²’è¨­å¥½ï¼‰
    if not BUCKET_NAME:
        print("âŒ éŒ¯èª¤: éšæ®µäºŒæ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸ GCS_BUCKET_NAME")
        sys.exit(1)

    # å®šç¾©è·¯å¾‘ï¼šè®€å–å…¨å°ç¸½è¡¨ï¼Œä¸¦å°‡æ¨™ç±¤å­˜å…¥æ¨™ç±¤ç¸½è¡¨
    BASE_CSV_PATH = "raw/store/base.csv"
    TAGS_TOTAL_PATH = "raw/tag/tags_total.csv"

    print(f"\n" + "="*50)
    print(f"ğŸš€ [Tag Scraper] å¢é‡æ¨¡å¼å•Ÿå‹•")
    print(f"ğŸ“ ç›®æ¨™å€åŸŸ: {REGION} | é™åˆ¶ç­†æ•¸: {SCAN_LIMIT if SCAN_LIMIT else 'ç„¡'}")
    print(f"="*50)

    # --- æ­¥é©Ÿ 1: è®€å–åå–®èˆ‡æ’é‡ ---
    # è®€å– Step 1 ç”¢å‡ºçš„å…¨å°åº—å®¶ç¸½è¡¨
    full_df = load_csv_from_gcs(BUCKET_NAME, BASE_CSV_PATH)
    if full_df is None or full_df.empty:
        print("âŒ æ‰¾ä¸åˆ°åº—å®¶ç¸½è¡¨ (base.csv)ï¼Œè«‹å…ˆåŸ·è¡Œ Step 1")
        sys.exit(1)

    # è®€å–å·²ç¶“çˆ¬éçš„æ¨™ç±¤ç¸½è¡¨
    df_existing_tags = load_csv_from_gcs(BUCKET_NAME, TAGS_TOTAL_PATH)
    
    # è¨ˆç®—ã€Œå°šæœªçˆ¬å–ã€çš„åå–®
    if df_existing_tags is not None and not df_existing_tags.empty:
        done_ids = set(df_existing_tags['place_id'].unique())
        # æ’é™¤æ‰å·²ç¶“åœ¨æ¨™ç±¤ç¸½è¡¨è£¡çš„åº—å®¶
        df_to_process = full_df[~full_df['place_id'].isin(done_ids)]
        print(f"ğŸ“Š ç¸½è¡¨å…±æœ‰ {len(full_df)} ç­†ï¼Œå·²å®Œæˆ {len(done_ids)} ç­†ã€‚")
    else:
        df_to_process = full_df
        df_existing_tags = pd.DataFrame()
        print("ğŸ“Š æ¨™ç±¤ç¸½è¡¨å°šæœªå»ºç«‹ï¼Œå°‡å¾é ­é–‹å§‹çˆ¬å–ã€‚")

    # å¥—ç”¨æƒææ•¸é‡é™åˆ¶
    if SCAN_LIMIT:
        df_to_process = df_to_process.head(SCAN_LIMIT)

    if df_to_process.empty:
        print("âœ… æ‰€æœ‰åº—å®¶çš†å·²çˆ¬å–å®Œç•¢ï¼Œç„¡éœ€åŸ·è¡Œã€‚")
        sys.exit(0)

    print(f"ğŸ“ æœ¬æ¬¡æº–å‚™çˆ¬å– {len(df_to_process)} ç­†æ–°åº—å®¶...\n")

    # --- æ­¥é©Ÿ 2: åˆå§‹åŒ– Selenium ---
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--lang=zh-TW") # å¼·åˆ¶ä¸­æ–‡ï¼Œç¢ºä¿è§£ææ­£ç¢º
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    
    new_tag_records = []
    payment_patch = {} # ç”¨æ–¼å›å¡«æ”¯ä»˜æ–¹å¼

    # --- æ­¥é©Ÿ 3: åŸ·è¡Œçˆ¬å– ---
    try:
        for index, row in df_to_process.iterrows():
            place_id = row.get('place_id')
            name = row.get('name')
            address = row.get('formatted_address', '')
            
            # ğŸŒŸ é—œéµ 1ï¼šè®Šæ•¸åˆå§‹åŒ– (æ”¾åœ¨æœå°‹å‰ï¼Œç¢ºä¿å‡ºéŒ¯ä¹Ÿä¸æœƒå ± NameError)
            beautiful_text, payment_options = "", ""
            raw_content = ""
            
            query = f"{name} {str(address)[:10]}"
            print(f"ğŸ” [{index+1}/{len(df_to_process)}] æœå°‹: {name}")

            try:
                # ğŸŒŸ é—œéµ 2ï¼šå›åˆ°æ‰“å­—æœå°‹æµç¨‹
                # A. å…ˆå‰å¾€ä¸»é é¢
                driver.get("https://www.google.com/maps?hl=zh-TW")
                time.sleep(random.uniform(2, 3)) 

                # --- B. æ‰¾åˆ°æœå°‹æ¡†ã€è¼¸å…¥ä¸¦ Enter (ç©©å®šç‰ˆ) ---
                try:
                    # å»ºç«‹ä¸€å€‹æœ€å¤šç­‰ 15 ç§’çš„ã€Œç›£è¦–å™¨ã€
                    wait = WebDriverWait(driver, 15)
                    
                    # ğŸŒŸ é—œéµï¼šç­‰åˆ°æœå°‹æ¡†ã€ŒçœŸçš„å‡ºç¾åœ¨ DOMã€ä¸”ã€Œå¯ä»¥è¢«çœ‹åˆ°ã€
                    search_box = wait.until(
                        EC.visibility_of_element_located((By.ID, "searchboxinput"))
                    )
                    
                    search_box.clear()
                    search_box.send_keys(query)
                    search_box.send_keys(Keys.ENTER)
                    
                    # é€™è£¡å¯ä»¥ä¿ç•™ä¸€é»é» time.sleepï¼Œè®“é é¢æœ‰æ™‚é–“é–‹å§‹è·³è½‰
                    time.sleep(random.uniform(2, 3)) 

                except Exception as e:
                    print(f"âŒ æœå°‹æ¡†ç­‰å¤ªä¹…æ²’å‡ºç¾ï¼Œç›®å‰ç¶²å€: {driver.current_url}")
                    # é€™è£¡å¯ä»¥é¸æ“‡å ±éŒ¯æˆ–æ˜¯æˆªåœ–åµéŒ¯
                    raise e

                # C. å¦‚æœæœå°‹çµæœæ˜¯åˆ—è¡¨ï¼Œé»æ“Šç¬¬ä¸€å€‹
                list_items = driver.find_elements(By.CLASS_NAME, "hfpxzc")
                if list_items:
                    list_items[0].click()
                    time.sleep(2)

                # D. é»æ“Šã€Œé—œæ–¼ (About)ã€
                try:
                    # ä½¿ç”¨å¤šé‡æ¢ä»¶ XPATH ä»¥æé«˜ç©©å®šæ€§
                    about_btn = driver.find_element(By.XPATH, "//button[contains(@aria-label, 'é—œæ–¼') or contains(@aria-label, 'ç°¡ä»‹') or .//div[text()='é—œæ–¼']]")
                    driver.execute_script("arguments[0].click();", about_btn) # ä½¿ç”¨ JS é»æ“Šè¼ƒä¸å—é®æ“‹å½±éŸ¿
                    time.sleep(2)
                except Exception:
                    print(f" â„¹ï¸  {name} ç„¡æ³•é»æ“Šã€Œé—œæ–¼ã€åˆ†é ï¼Œå¯èƒ½ç›´æ¥é¡¯ç¤ºåœ¨ä¸»é æˆ–ç„¡ç°¡ä»‹ã€‚")

                # E. è§£ææ¨™ç±¤
                soup = BeautifulSoup(driver.page_source, "html.parser")
                info_blocks = soup.select('div[role="region"].m6QErb div.iP2t7d')
                for b in info_blocks:
                    raw_content += b.get_text(separator="\n") + "\n"

                # ğŸŒŸ é—œéµ 3ï¼šå°‡è§£æå‡ºçš„ raw_content ä¸Ÿé€²æ¸…æ´—å‡½å¼
                if raw_content.strip():
                    beautiful_text, payment_options = clean_google_tags_final(raw_content)

                # F. æ”¶é›†çµæœè‡³å®¹å™¨
                if payment_patch is not None and payment_options:
                    payment_patch[place_id] = payment_options
                    print(f"    ğŸ’° æ”¯ä»˜æ–¹å¼: {payment_options}")

                if beautiful_text:
                    for section in beautiful_text.split(" || "):
                        new_tag_records.append({
                            'name': name,
                            'place_id': place_id,
                            'Tag': section,
                            'data_source': 'google_about_tab',
                            'crawled_at': time.strftime('%Y-%m-%d %H:%M:%S')
                        })
                    print(f"    âœ… æ¨™ç±¤æ¡é›†æˆåŠŸ")
                else:
                    print(f"    âš ï¸ æœªèƒ½è§£æåˆ°æœ‰æ•ˆæ¨™ç±¤")

            except Exception as e:
                print(f"    âŒ {name} æœå°‹éç¨‹å‡ºéŒ¯: {e}")
            
            # æ¯è·‘å®Œä¸€å®¶åº—ä¼‘æ¯ä¸€ä¸‹
            time.sleep(random.uniform(2, 4))
    except Exception as global_e:
        print(f"ğŸš¨ åŸ·è¡Œéç¨‹ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {global_e}")

    # --- æ­¥é©Ÿ 4: åˆä½µæ–°èˆŠè³‡æ–™ä¸¦å„²å­˜ ---
    if new_tag_records:
        print(f"\nğŸ“¦ æ­£åœ¨æ•´åˆè³‡æ–™ä¸¦å›å¯« GCS...")
        df_new_tags = pd.DataFrame(new_tag_records)
        
        # åˆä½µèˆŠæœ‰çš„æ¨™ç±¤èˆ‡æœ¬æ¬¡æ–°æŠ“çš„æ¨™ç±¤
        df_final_tags = pd.concat([df_existing_tags, df_new_tags], ignore_index=True)
        # å»é‡ï¼šç¢ºä¿åŒä¸€å€‹ place_id ä¸‹æ²’æœ‰é‡è¤‡çš„ Tag å…§å®¹
        df_final_tags = df_final_tags.drop_duplicates(subset=['place_id', 'Tag'], keep='first')
        
        # è¦†å¯«å› GCS ç¸½è¡¨ (è®“ä¸‹æ¬¡åŸ·è¡Œèƒ½è¾¨è­˜å·²å®Œæˆ)
        upload_df_to_gcs(df_final_tags, BUCKET_NAME, TAGS_TOTAL_PATH)
        
        # å¦å­˜ä¸€ä»½ç•¶æ¬¡çš„å‚™ä»½æª”æ¡ˆ (Archive)
        timestamp = time.strftime('%Y%m%d_%H%M')
        archive_path = f"raw/tag/archive/tags_{REGION}_{timestamp}.csv"
        upload_df_to_gcs(df_new_tags, BUCKET_NAME, archive_path)
        
        print(f"âœ… æ¨™ç±¤ç¸½è¡¨æ›´æ–°æˆåŠŸï¼Œç›®å‰å…± {len(df_final_tags)} ç­†è¨˜éŒ„ã€‚")
    else:
        print("â„¹ï¸ æœ¬æ¬¡æœªæ¡é›†åˆ°æ–°æ¨™ç±¤ã€‚")

    if payment_patch:
        print("\nğŸ”„ æ­£åœ¨å°‡æ”¯ä»˜æ–¹å¼æ›´æ–°å›åº—å®¶ç¸½è¡¨...")
        # å°‡æ–°æŠ“åˆ°çš„æ”¯ä»˜æ–¹å¼å°æ‡‰å›åŸæœ¬çš„ full_df
        full_df['payment_options'] = full_df['place_id'].map(payment_patch).fillna(full_df.get('payment_options', ''))
        
        # è¦†å¯«å› GCS ä¸Šçš„ base.csv
        upload_df_to_gcs(full_df, BUCKET_NAME, BASE_CSV_PATH)
        print("âœ… åº—å®¶ç¸½è¡¨ (base.csv) æ”¯ä»˜æ–¹å¼æ›´æ–°å®Œæˆã€‚")

    print(f"ğŸ‰ å€åŸŸ {REGION} è™•ç†çµæŸï¼")