import sys
import os
import time
import io
import pandas as pd
import googlemaps
from google.cloud import storage, secretmanager
from src.config.regions import CAFE_REGIONS, MODE_HIGH, MODE_LOW

# --- 1. è·¯å¾‘è¨­å®š (ä¿ç•™ä»¥ç¢ºä¿æ¨¡çµ„å¼•ç”¨æ­£å¸¸) ---
root_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if root_path not in sys.path:
    sys.path.append(root_path)

# å‡è¨­ src.config.regions å­˜åœ¨æ–¼ä½ çš„å°ˆæ¡ˆçµæ§‹ä¸­
try:
    from src.config.regions import CAFE_REGIONS, MODE_HIGH
except ImportError:
    # é é˜²æ€§éŒ¯èª¤è™•ç†ï¼Œè‹¥åœ¨å–®æª”æ¸¬è©¦æ™‚æ²’æœ‰ config æª”
    print("âš ï¸ è­¦å‘Š: ç„¡æ³•åŒ¯å…¥ src.config.regionsï¼Œè«‹ç¢ºä¿å°ˆæ¡ˆçµæ§‹æ­£ç¢ºã€‚")
    CAFE_REGIONS = {} 
    MODE_HIGH = "high"

# --- 2. é›²ç«¯å·¥å…·å‡½å¼ ---

def get_secret(secret_resource_name):
    """
    å¾ Google Secret Manager ç²å–æ•æ„Ÿè³‡è¨Š (API Key)
    æ ¼å¼: projects/{project_id}/secrets/{secret_id}/versions/latest
    """
    client = secretmanager.SecretManagerServiceClient()
    try:
        response = client.access_secret_version(request={"name": secret_resource_name})
        return response.payload.data.decode("UTF-8")
    except Exception as e:
        print(f"âŒ ç„¡æ³•å­˜å– Secret Manager ({secret_resource_name}): {e}")
        # åœ¨ Cloud Run ä¸­ï¼Œé€™æœƒå°è‡´å®¹å™¨å´©æ½°ä¸¦é‡æ–°å•Ÿå‹• (CrashLoopBackOff)ï¼Œé€™æ˜¯é æœŸè¡Œç‚º
        sys.exit(1)

def upload_to_gcs(df, bucket_name, destination_blob_name):
    """
    å°‡ DataFrame ç›´æ¥è½‰ç‚º CSV ä¸¦ä¸Šå‚³è‡³ GCS (ä¸è½åœ°)
    """
    try:
        client = storage.Client()
        bucket = client.bucket(bucket_name)
        blob = bucket.blob(destination_blob_name)

        # ä½¿ç”¨è¨˜æ†¶é«”ç·©è¡å€ï¼Œé¿å…å¯«å…¥å®¹å™¨ç¡¬ç¢Ÿ
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        
        blob.upload_from_string(csv_buffer.getvalue(), content_type='text/csv')
        print(f"âœ… ä¸Šå‚³æˆåŠŸ: gs://{bucket_name}/{destination_blob_name}")
    except Exception as e:
        print(f"âŒ ä¸Šå‚³ GCS å¤±æ•—: {e}")

# --- 3. æ ¸å¿ƒé‚è¼¯ï¼šç¶²æ ¼æœå°‹ (ä¿ç•™åŸå§‹é‚è¼¯) ---
def get_cafes_with_grid(gmaps_client, lat, lng, rad, offset, mode, limit=None):
    if mode == MODE_HIGH:
        points = [(lat + i * offset, lng + j * offset) for i in [-1, 0, 1] for j in [-1, 0, 1]]
    else:
        points = [(lat, lng), (lat+offset, lng), (lat-offset, lng), (lat, lng+offset), (lat, lng-offset)]

    all_basic_results = []
    print(f"ğŸš€ å•Ÿå‹•ç¶²æ ¼æƒæ...")

    for i, (p_lat, p_lng) in enumerate(points):
        next_page_token = None
        while True:
            try:
                res = gmaps_client.places(
                    query='å’–å•¡å»³ OR å’–å•¡åº—',
                    location=(p_lat, p_lng),
                    radius=rad,
                    language='zh-TW',
                    page_token=next_page_token
                )
                all_basic_results.extend(res.get('results', []))
                next_page_token = res.get('next_page_token')
                if not next_page_token: break
                time.sleep(2)
            except Exception as e:
                print(f"âš ï¸ Places API è«‹æ±‚éŒ¯èª¤: {e}")
                break

    unique_places = list({p['place_id']: p for p in all_basic_results}.values())
    if limit:
        unique_places = unique_places[:limit]
        print(f" å·²å¥—ç”¨æ•¸é‡é™åˆ¶ï¼š{len(unique_places)} ç­†")
    return unique_places

# --- 4. æ ¸å¿ƒé‚è¼¯ï¼šè©³ç´°è³‡æ–™æŠ“å– (ä¿ç•™åŸå§‹é‚è¼¯) ---
def fetch_details(gmaps_client, unique_places):
    store_list = []
    dynamic_list = []
    print(f"\n é–‹å§‹è©³ç´°æ¬„ä½æ¡é›† (å…± {len(unique_places)} ç­†)...")

    for idx, place in enumerate(unique_places):
        p_id = place['place_id']
        name = place['name']
        loc = place.get('geometry', {}).get('location', {})
        print(f"[{idx+1}/{len(unique_places)}] æ­£åœ¨æ¡é›†: {name}")

        try:
            details = gmaps_client.place(
                place_id=p_id,
                fields=[
                    'formatted_phone_number', 
                    'website', 
                    'rating', 
                    'opening_hours', 
                    'price_level', 
                    'business_status', 
                    'type', 
                    'user_ratings_total'
                ],
                language='zh-TW'
            ).get('result', {})
        except Exception as e:
            print(f"    {name} æ¡é›†å¤±æ•—: {e}")
            details = {}

        # è³‡æ–™æ¸…æ´—èˆ‡è½‰æ›
        weekday_text = details.get('opening_hours', {}).get('weekday_text', [])
        f_opening = " | ".join(weekday_text) if weekday_text else None
        
        raw_type = details.get('type') or place.get('types', [])
        f_types = ",".join(raw_type) if isinstance(raw_type, list) else str(raw_type)

        # --- A. Store Table ---
        store_list.append({
            'name': name,
            'place_id': p_id,
            'formatted_phone_number': details.get('formatted_phone_number'),
            'formatted_address': place.get('formatted_address'),
            'website': details.get('website'),
            'location': f"POINT({loc.get('lng')} {loc.get('lat')})" if loc else None,
            'opening_hours': f_opening,
            'price_level': details.get('price_level'),
            'business_status': details.get('business_status'),
            'types': f_types,
            'payment_options': "" 
        })

        # --- B. Store_Dynamic_Feedback Table ---
        dynamic_list.append({
            'place_id': p_id,
            'name': name,
            'rating': details.get('rating'),
            'user_ratings_total': details.get('user_ratings_total'),
            'data_source': 'Google_Maps_API',
            'processed_at': time.strftime('%Y-%m-%d %H:%M:%S')
        })
        time.sleep(0.5)

    return store_list, dynamic_list

# --- 5. å¤§è…¦æ§åˆ¶ä¸­å¿ƒ (Cloud Run å…¥å£) ---
if __name__ == "__main__":
    print(f"\n" + "="*40)
    print(f"â˜ï¸ [TJR104 Cloud Run çˆ¬èŸ²ç³»çµ±å•Ÿå‹•]")
    
    # 1. è®€å– Cloud Run ç’°å¢ƒè®Šæ•¸
    # æ³¨æ„ï¼šé€™äº›è®Šæ•¸å¿…é ˆåœ¨ Cloud Run çš„ã€Œè®Šæ•¸èˆ‡ç¥•å¯†ã€é é¢è¨­å®š
    SECRET_RESOURCE_NAME = os.getenv("SECRET_RESOURCE_NAME")
    BUCKET_NAME = os.getenv("GCS_BUCKET_NAME")
    
    SCAN_ALL = os.getenv("SCAN_ALL", "false").lower() == "true"
    SCAN_REGION = os.getenv("SCAN_REGION", "A-2")
    SCAN_LIMIT_RAW = os.getenv("SCAN_LIMIT")
    SCAN_LIMIT = int(SCAN_LIMIT_RAW) if (SCAN_LIMIT_RAW and SCAN_LIMIT_RAW.isdigit()) else None
    
    # æª¢æŸ¥å¿…è¦è®Šæ•¸
    if not SECRET_RESOURCE_NAME or not BUCKET_NAME:
        print("âŒ éŒ¯èª¤: ç¼ºå°‘å¿…è¦ç’°å¢ƒè®Šæ•¸ (SECRET_RESOURCE_NAME æˆ– GCS_BUCKET_NAME)")
        sys.exit(1)

    print(f"   - Target Bucket: {BUCKET_NAME}")
    print(f"   - Scan Mode: {'ALL Regions' if SCAN_ALL else f'Region {SCAN_REGION}'}")
    print(f"   - Limit: {SCAN_LIMIT if SCAN_LIMIT else 'No Limit'}")
    print("="*40 + "\n")

    # 2. åˆå§‹åŒ– Google Maps Client (å¾ Secret Manager æ‹¿ Key)
    api_key = get_secret(SECRET_RESOURCE_NAME)
    gmaps = googlemaps.Client(key=api_key)

    # 3. æ±ºå®šåŸ·è¡Œç¯„åœ
    run_list = list(CAFE_REGIONS.keys()) if SCAN_ALL else [SCAN_REGION]

    # 4. åŸ·è¡Œä»»å‹™å¾ªç’°
    for r_id in run_list:
        cfg = CAFE_REGIONS.get(r_id)
        if not cfg: 
            print(f"âš ï¸ æ‰¾ä¸åˆ°å€åŸŸè¨­å®š: {r_id}ï¼Œè·³éã€‚")
            continue
        
        print(f"\nğŸ“ æ­£åœ¨è™•ç†å€åŸŸ: {r_id} ...")
        
        # (A) æœå°‹
        basic_list = get_cafes_with_grid(
            gmaps, cfg['lat'], cfg['lng'], cfg['radius'], cfg['offset'], cfg['mode'], limit=SCAN_LIMIT
        )
        
        if not basic_list:
            print(f"   å€åŸŸ {r_id} æœªæ‰¾åˆ°ä»»ä½•åº—å®¶ã€‚")
            continue

        # (B) æŠ“ç´°ç¯€
        store_data, dynamic_data = fetch_details(gmaps, basic_list)

        # (C) æº–å‚™ä¸Šå‚³ GCS
        # åŠ å…¥æ™‚é–“æˆ³è¨˜ä»¥åˆ© Airflow è¾¨è­˜æ–°æª”æ¡ˆ
        timestamp = time.strftime('%Y%m%d_%H%M')

        # ä¸Šå‚³ Store Base Data
        if store_data:
            upload_to_gcs(
                pd.DataFrame(store_data), 
                BUCKET_NAME, 
                f"raw/store/{r_id}_{timestamp}_base.csv"
            )
        
        # ä¸Šå‚³ Dynamic Data
        if dynamic_data:
            upload_to_gcs(
                pd.DataFrame(dynamic_data), 
                BUCKET_NAME, 
                f"raw/store_dynamic/{r_id}_{timestamp}_dynamic.csv"
            )
            
        print(f"âœ¨ å€åŸŸ {r_id} è™•ç†å®Œæˆã€‚")

    print("\nâœ… æ‰€æœ‰æ¡é›†ä»»å‹™èˆ‡é›²ç«¯åŒæ­¥å·²çµæŸï¼")