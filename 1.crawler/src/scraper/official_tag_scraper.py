import sys
import os
import time
import random
import io
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from google.cloud import storage
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException

# --- 1. é›²ç«¯å·¥å…·å‡½æ•¸ ---
def get_gcs_client():
    return storage.Client()

def load_csv_from_gcs(bucket_name, blob_name):
    """å¾ GCS è®€å– CSV"""
    client = get_gcs_client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)
    if not blob.exists():
        return None
    content = blob.download_as_string()
    return pd.read_csv(io.BytesIO(content))

def upload_df_to_gcs(df, bucket_name, blob_name):
    """ä¸Šå‚³ DataFrame åˆ° GCS"""
    client = get_gcs_client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)
    csv_buffer = io.StringIO()
    df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
    blob.upload_from_string(csv_buffer.getvalue(), content_type='text/csv')
    print(f" å·²å„²å­˜è‡³: gs://{bucket_name}/{blob_name}")

# --- 2. æ¨™ç±¤æ¸…æ´—å‡½å¼ ---
def clean_google_tags_final(raw_content):
    if not raw_content: return "", ""
    lines = [l.strip() for l in raw_content.split('\n') if l.strip()]
    unique_lines = []
    [unique_lines.append(x) for x in lines if x not in unique_lines]

    formatted_sections = []
    payment_methods = []
    
    for section in unique_lines:
        if "î€³" in section or "[ç„¡]" in section: continue
        if 'î—Š' in section:
            parts = section.split('î—Š')
            category = parts[0].strip()
            items_list = [p.strip() for p in parts[1:] if p.strip()]
            items_str = " | ".join(items_list)
            formatted_sections.append(f"{category}ï¼š{items_str}")
            if "ä»˜æ¬¾" in category:
                payment_methods.extend(items_list)

    full_tags_text = " || ".join(formatted_sections)
    payment_options_str = ",".join(payment_methods) if payment_methods else ""
    return full_tags_text, payment_options_str

# --- 3. æ¨¡çµ„åŒ–å…¥å£ (è¢« main.py å‘¼å«) ---
def run(region="A-2", total_shards=1, shard_index=0):
    """
    åŸ·è¡Œå®˜æ–¹æ¨™ç±¤èˆ‡ç¶²å€æ¡é›†ä»»å‹™ (æ”¯æ´åˆ†ç‰‡)
    """
    BUCKET_NAME = os.getenv("GCS_BUCKET_NAME", "tjr104-cafe-datalake")
    ENV_LIMIT = os.getenv("SCAN_LIMIT")
    SCAN_LIMIT = int(ENV_LIMIT) if (ENV_LIMIT and ENV_LIMIT.isdigit()) else None

    if not BUCKET_NAME:
        print(" éŒ¯èª¤: æ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸ GCS_BUCKET_NAME")
        sys.exit(1)

    # è·¯å¾‘è¨­å®š
    BASE_CSV_PATH = "raw/store/base.csv"
    
    # [ä¿®æ”¹é» 1] è¼¸å‡ºæª”åæ”¹ç‚ºåˆ†ç‰‡æ ¼å¼ï¼Œé¿å…è¡çª
    # æ¨™ç±¤æª”
    TAGS_PART_PATH = f"raw/tag/parts/tags_official_{region}_part_{shard_index}.csv"
    # Base æ›´æ–°æª” (URL/Payment)
    BASE_UPDATE_PATH = f"raw/store/parts/base_update_{region}_part_{shard_index}.csv"

    print(f"ğŸš€ [Official Tags] æ¨¡çµ„å•Ÿå‹• | åˆ†ç‰‡ {shard_index+1}/{total_shards} | å€åŸŸ: {region}")

    full_df = load_csv_from_gcs(BUCKET_NAME, BASE_CSV_PATH)
    if full_df is None or full_df.empty:
        print(" æ‰¾ä¸åˆ° base.csv")
        sys.exit(1)

    # [ä¿®æ”¹é» 2] åŸ·è¡Œåˆ†ç‰‡åˆ‡åˆ† (Sharding)
    # åªä¿ç•™é¤˜æ•¸ç­‰æ–¼ç•¶å‰ shard_index çš„è³‡æ–™
    df_to_process = full_df[full_df.index % total_shards == shard_index].copy()
    print(f"ğŸ“Š æœ¬åˆ†ç‰‡åˆ†é…åˆ° {len(df_to_process)} ç­†ä»»å‹™ (ç¸½æ•¸ {len(full_df)})")

    # ç°¡å–®éæ¿¾ï¼šæ ¹æ“š SCAN_LIMIT è·‘ (å¦‚æœæ˜¯æ¸¬è©¦æ¨¡å¼)
    if SCAN_LIMIT:
        df_to_process = df_to_process.head(SCAN_LIMIT)
        print(f" æ¸¬è©¦æ¨¡å¼: åƒ…åŸ·è¡Œå‰ {SCAN_LIMIT} ç­†")

    # åˆå§‹åŒ– Selenium
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=900,1000")
    chrome_options.add_argument("--lang=zh-TW")
    # ç¦æ­¢åœ–ç‰‡ (åŠ é€Ÿ)
    prefs = {"profile.managed_default_content_settings.images": 2}
    chrome_options.add_experimental_option("prefs", prefs)
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    wait = WebDriverWait(driver, 15)
    
    batch_size = 3
    
    # æš«å­˜å®¹å™¨
    new_tag_records = []
    base_updates = [] # å­˜ place_id, url, payment_options

    try:
        # ä½¿ç”¨ enumerate é‡æ–°è¨ˆæ•¸ (å› ç‚º index è¢«åˆ‡åˆ†å¾Œä¸é€£çºŒ)
        for i, (idx, row) in enumerate(df_to_process.iterrows(), 1):
            place_id = row.get('place_id')
            name = row.get('name')
            address = row.get('formatted_address', '')
            
            # æ‰¹æ¬¡é‡å•Ÿ
            if (i - 1) % batch_size == 0 and i > 1:
                driver.quit()
                driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
                wait = WebDriverWait(driver, 15)

            query = f"{name} {str(address)[:10]}"
            print(f"[{i}/{len(df_to_process)}]  æœå°‹: {name}")

            try:
                driver.get("https://www.google.com.tw/maps")
                time.sleep(1)
                
                # Cookie è™•ç†
                try:
                    btn = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "button[aria-label*='å…¨éƒ¨æ¥å—'], button[aria-label*='Accept all']")))
                    btn.click()
                except: pass

                box = driver.find_element(By.NAME, "q")
                box.clear()
                box.send_keys(query + Keys.ENTER)
                time.sleep(3)

                items = driver.find_elements(By.CLASS_NAME, "hfpxzc")
                if items:
                    items[0].click()
                    time.sleep(2)

                # æŠ“å–ç•¶å‰ Google Maps ç¶²å€
                current_url = driver.current_url
                
                # é»æ“Šé—œæ–¼
                beautiful_text = ""
                payment_options = ""
                
                try:
                    about_btn = wait.until(EC.element_to_be_clickable((By.XPATH, "//button[contains(@aria-label, 'é—œæ–¼') or contains(@aria-label, 'ç°¡ä»‹')]")))
                    driver.execute_script("arguments[0].click();", about_btn)
                    wait.until(EC.text_to_be_present_in_element((By.CSS_SELECTOR, 'div[role="region"]'), "î—Š"))
                    time.sleep(1)
                    
                    # è§£æ
                    soup = BeautifulSoup(driver.page_source, "html.parser")
                    info_blocks = soup.select('div[role="region"].m6QErb div.iP2t7d')
                    raw_content = "\n".join([b.text for b in info_blocks])
                    beautiful_text, payment_options = clean_google_tags_final(raw_content)

                except:
                    # print(f"    ç„¡æ³•é€²å…¥ç°¡ä»‹é ")
                    pass

                # æ”¶é›† Tag è³‡æ–™
                if beautiful_text:
                    for section in beautiful_text.split(" || "):
                        new_tag_records.append({
                            'name': name,
                            'place_id': place_id,
                            'Tag': section,
                            'Tag_id': "PENDING",
                            'data_source': 'googleç°¡ä»‹æ¨™ç±¤'
                        })
                    # print(f"    æ¨™ç±¤å·²æŠ“å–")

                # æ”¶é›† Base Update è³‡æ–™ (URL & Payment)
                base_updates.append({
                    'place_id': place_id,
                    'google_maps_url': current_url,
                    'payment_options': payment_options
                })

            except Exception as e:
                print(f"     éŒ¯èª¤: {e}")
                continue
            
            time.sleep(random.uniform(1, 2))

            # --- [ä¿®æ”¹é» 3] ä¸­é€”å­˜æª” (å­˜æˆåˆ†ç‰‡æª”ï¼Œä¸è®€å–èˆŠæª”ï¼Œç›´æ¥ append æˆ– overwrite) ---
            # ç‚ºäº†ç°¡åŒ–é‚è¼¯ï¼Œæˆ‘å€‘é€™è£¡æ¡ç”¨ã€Œç´¯ç©ä¸€å®šé‡å¾Œå­˜æª”ã€
            if i % batch_size == 0:
                print(f" ä¸­é€”å¯«å…¥åˆ†ç‰‡æª”...")
                if new_tag_records:
                    df_tags = pd.DataFrame(new_tag_records)
                    # è®€å–è‡ªå·±å·²ç¶“å­˜éçš„ part file (append mode)
                    existing_part = load_csv_from_gcs(BUCKET_NAME, TAGS_PART_PATH)
                    if existing_part is not None:
                        df_tags = pd.concat([existing_part, df_tags], ignore_index=True)
                    
                    upload_df_to_gcs(df_tags.drop_duplicates(), BUCKET_NAME, TAGS_PART_PATH)
                    new_tag_records = [] # æ¸…ç©º

                if base_updates:
                    df_updates = pd.DataFrame(base_updates)
                    existing_part = load_csv_from_gcs(BUCKET_NAME, BASE_UPDATE_PATH)
                    if existing_part is not None:
                        df_updates = pd.concat([existing_part, df_updates], ignore_index=True)

                    upload_df_to_gcs(df_updates.drop_duplicates(subset=['place_id']), BUCKET_NAME, BASE_UPDATE_PATH)
                    base_updates = [] # æ¸…ç©º

    finally:
        driver.quit()

    # --- æœ€çµ‚å­˜æª” ---
    print("\n åŸ·è¡Œæœ€çµ‚å­˜æª”...")
    if new_tag_records:
        df_tags = pd.DataFrame(new_tag_records)
        existing_part = load_csv_from_gcs(BUCKET_NAME, TAGS_PART_PATH)
        if existing_part is not None:
            df_tags = pd.concat([existing_part, df_tags], ignore_index=True)
        upload_df_to_gcs(df_tags.drop_duplicates(), BUCKET_NAME, TAGS_PART_PATH)

    if base_updates:
        df_updates = pd.DataFrame(base_updates)
        existing_part = load_csv_from_gcs(BUCKET_NAME, BASE_UPDATE_PATH)
        if existing_part is not None:
            df_updates = pd.concat([existing_part, df_updates], ignore_index=True)
        upload_df_to_gcs(df_updates.drop_duplicates(subset=['place_id']), BUCKET_NAME, BASE_UPDATE_PATH)

    print(" Official Tags åˆ†ç‰‡ä»»å‹™çµæŸï¼")