""" 
    åˆ¤æ–·æ˜¯å¦ç‚ºè‡ªç„¶èªè¨€ or Tag
        1. è‡ªç„¶èªè¨€:AIå°‡è‡ªç„¶èªè¨€è½‰å‘é‡(å·²æˆåŠŸembedding 1536æœå°‹åŠŸèƒ½)
                    -> é‡å° reviews (è©•è«–) é›†åˆé€²è¡Œå‘é‡ç›¸ä¼¼åº¦æœå°‹
                    -> æœåˆ°è©•è«–å¾Œï¼Œç”¨ $lookup æŠŠå°æ‡‰çš„ cafes (åº—å®¶è³‡æ–™) æŠ“é€²ä¾†
                    -> éæ¿¾é»‘åå–®
                    -> Python Filter (éæ¿¾èˆ‡è©•åˆ†éšæ®µ)
                        å‰”é™¤è·é›¢ > 3000 å…¬å°º (3km) çš„çµæœï¼Œå–å‰10å
            ä¾‹å¤–è™•ç†ï¼šå¦‚æœ AI å‘é‡ç”Ÿæˆå¤±æ•—ï¼Œå°‡ user_query ç•¶ä½œæ™®é€šé—œéµå­—ï¼Œå¼·åˆ¶è½‰å…¥ è·¯å¾‘ B
                   
                           
        2. Tag:è·¯å¾‘ Bï¼šå‚³çµ±æ¨™ç±¤/åœ°ç†æœå°‹ (Geo + Keyword Match)
            -> åœ°ç†ç¯©é¸ ($geoNear)ï¼šç›´æ¥åœ¨è³‡æ–™åº«å±¤ç´šæ‰¾å‡ºæ–¹åœ“ 3000 å…¬å°ºå…§çš„åº—å®¶ï¼ˆé€™æ˜¯æœ€å„ªå…ˆæ¢ä»¶ï¼‰
            -> éæ¿¾é»‘åå–®
            -> æ¨¡ç³Šæœå°‹ (Regex Match)é—œéµå­—
            -> å–å‰10ç­†
                               
    fast api å•Ÿå‹•
    uvicorn <æª”å>:app --reload
    .\ngrok.exe http 8000
"""


import os
import logging
from typing import Optional, List
from contextlib import asynccontextmanager
from datetime import datetime

# ç¬¬ä¸‰æ–¹å¥—ä»¶
from fastapi import FastAPI, Query, HTTPException
from pydantic import BaseModel
import gc
from google import genai
from google.genai import types
from geopy.distance import geodesic
from dotenv import load_dotenv
# è‡ªå®šç¾©æ¨¡çµ„
from database import db_client


# --- è¨­å®šèˆ‡åˆå§‹åŒ– ---
load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Coffee_Recommender")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if GEMINI_API_KEY:
    client = genai.Client(api_key=GEMINI_API_KEY)
else:
    logger.warning("âš ï¸ æ‰¾ä¸åˆ° GEMINI_API_KEY")



# ---è³‡æ–™æ¨¡å‹---
class UserLocation(BaseModel):
    lat: float
    lng: float


class UserLog(BaseModel):
    user_id: str
    action: str
    place_id: Optional[str] = None
    reason: Optional[str] = None

# ------------
# --- ç”Ÿå‘½é€±æœŸç®¡ç† ---

@asynccontextmanager
async def lifespan(app: FastAPI):
    try:
        db_client.connect()
        logger.info("âœ… è³‡æ–™åº«é€£ç·šå·²å»ºç«‹")
        yield
    except Exception as e:
        logger.error(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
        raise e
    finally:
        db_client.close()

app = FastAPI(lifespan=lifespan)



# --- è¼”åŠ©å‡½å¼ ---
def get_embedding(text: str) -> Optional[List[float]]:
    """
    ä½¿ç”¨æ–°ç‰ˆ google-genai SDK å–å¾—å‘é‡
    æ¨¡å‹: models/gemini-embedding-001
    ç¶­åº¦: å¼·åˆ¶è¼¸å‡º 1536
    """
    try:
        # ç¢ºä¿å…¨åŸŸçš„ client å·²ç¶“æ­£ç¢ºåˆå§‹åŒ–
        if not client:
            logger.error("âŒ Gemini Client æœªåˆå§‹åŒ–ï¼Œè«‹æª¢æŸ¥ API Key è¨­å®š")
            return None
      

        # æ–°ç‰ˆèªæ³•å‘¼å«
        response = client.models.embed_content(
            model='models/gemini-embedding-001',
            contents=text,
            config={
                'task_type': 'RETRIEVAL_QUERY',
                'output_dimensionality': 1536  # <--- å¼·åˆ¶æŒ‡å®šè¼¸å‡ºç¶­åº¦ç‚º 1536
            }
        )     

        # å–å¾—å›å‚³çš„å‘é‡å€¼ (List[float])
        vector = response.embeddings[0].values       

        # é¡å¤–æª¢æŸ¥ï¼šç¢ºä¿å›å‚³çš„ç¶­åº¦ç¢ºå¯¦æ˜¯ 1536
        if len(vector) != 1536:
            logger.warning(f"âš ï¸ é æœŸç¶­åº¦ 1536ï¼Œä½†å›å‚³ç‚º {len(vector)}")           
        return vector
      
    except Exception as e:
        logger.error(f"âŒ [New SDK] Embedding Error: {e}")
        return None


# 1. æ¨è–¦å’–å•¡å»³ (Recommend)
@app.get("/recommend")
async def recommend_cafes(
    lat: float,
    lng: float,
    user_id: Optional[str] = None,
    cafe_tag: Optional[str] = Query(None, description="æ¨™ç±¤/æŒ‰éˆ• (Database Match)"),
    user_query: Optional[str] = Query(None, description="è‡ªç„¶èªè¨€ (Vector Search)")
):
    db = db_client.get_db()
    if db is None:
         raise HTTPException(status_code=503, detail="Database not available")

    user_loc = (lat, lng)
    final_data = []

    try:
        # ==========================================
        # 1. [å…±ç”¨é‚è¼¯] å–å¾—é»‘åå–®
        # ==========================================
        blacklist_ids = []
        if user_id:
            blacklist_logs = list(db['interaction_logs'].find(
                {"user_id": user_id, "action": "NO"},
                {"place_id": 1}
            ))
            # ç¢ºä¿æ¬„ä½å°æ‡‰ (å‡è¨­ log è£¡çš„ place_id å°æ‡‰ cafes çš„ place_id)
            blacklist_ids = [log['place_id'] for log in blacklist_logs]

        # ==========================================
        # è·¯å¾‘ A: AI èªæ„æœå°‹ (Retrieve -> Python Filter)
        # ==========================================
        if user_query:
            query_vector = get_embedding(user_query)

                    # --- åŠ å…¥é€™æ®µé©—è­‰ç¢¼ ---
                     
            if query_vector:
            # é€™è£¡å°å‡ºä¾†ï¼Œä»£è¡¨ä½¿ç”¨è€…æ˜¯ç”¨ã€Œæ‰“å­—ã€çš„ï¼Œä¸” AI æˆåŠŸé‹ä½œ
                logger.info(f"âœ… [AI èªæ„åˆ†ææˆåŠŸ]")
                logger.info(f"   - ç”¨æˆ¶è¼¸å…¥: {user_query}")
                logger.info(f"   - å‘é‡ç¶­åº¦: {len(query_vector)}") # ç›£æ§æ˜¯å¦ç‚º 1536
            else:
                logger.warning(f"âŒ [AI èªæ„åˆ†æå¤±æ•—] è¼¸å…¥: {user_query}")
            # ---------------------
           
            if query_vector:
                # A-1. å‘é‡æœå°‹ pipeline
                pipeline_vec = [
                    {
                        "$vectorSearch": {
                            "index": "vector_index",
                            "path": "embedding",
                            "queryVector": query_vector,
                            "numCandidates": 100,
                            "limit": 50
                        }
                    },
                    {
                        "$lookup": {
                            "from": "cafes",
                            "localField": "place_id",
                            "foreignField": "place_id",
                            "as": "cafe_info"
                        }
                    },
                    { "$unwind": "$cafe_info" },
                    # æŠ•å½±å› cafes çš„æ ¼å¼
                    {
                        "$project": {
                            "place_id": "$cafe_info.place_id",
                            "original_name": "$cafe_info.original_name",
                            "location": "$cafe_info.location",
                            "rating": "$cafe_info.total_ratings", # æˆ– rating
                            "attributes": "$cafe_info.attributes",
                            "ai_tags": "$cafe_info.ai_tags",
                            "vector_score": { "$meta": "vectorSearchScore" },
                            "matched_review": "$content"
                        }
                    }
                ]

                # A-2. åœ¨ MongoDB å±¤ç´šéæ¿¾é»‘åå–® (å¦‚æœæœ‰çš„è©±)
                if blacklist_ids:
                    pipeline_vec.append({
                        "$match": { "place_id": { "$nin": blacklist_ids } }
                    })

                raw_results = list(db['reviews'].aggregate(pipeline_vec))
               
                # A-3. [Python] è·é›¢è¨ˆç®— + è©•åˆ†å…¬å¼å¾©åˆ»
                filtered_results = []
                for item in raw_results:
                    if not item.get('location') or 'coordinates' not in item['location']:
                        continue

                    # åº§æ¨™è½‰æ› GeoJSON [lng, lat] -> Geopy (lat, lng)
                    cafe_loc = (item['location']['coordinates'][1], item['location']['coordinates'][0])
                    dist_meters = geodesic(user_loc, cafe_loc).meters
                   
                    if dist_meters <= 3000:
                        item['dist_meters'] = int(dist_meters)
                       
                        # --- [æ ¸å¿ƒ] é‡ç¾ä½ çš„è©•åˆ†å…¬å¼ ---
                        # åŸå…¬å¼: rating / (dist/100 + 1)
                        # AI ç‰ˆå…¬å¼: (å‘é‡åˆ†æ•¸ * rating) / (dist/100 + 1)
                        # é€™æ¨£æ—¢è€ƒé‡äº†èªæ„ç›¸ä¼¼åº¦(vector_score)ï¼Œä¹Ÿä¿ç•™äº†è·é›¢è¡°æ¸›é‚è¼¯
                        base_rating = item.get('rating', 0) or 0
                        vec_score = item.get('vector_score', 0.8)
                       
                        search_score = (base_rating * vec_score) / ((dist_meters / 100) + 1)
                       
                        item['search_score'] = search_score
                        filtered_results.append(item)
               
                filtered_results.sort(key=lambda x: x['search_score'], reverse=True)
                final_data = filtered_results[:10]
            else:
                # å‘é‡å¤±æ•—ï¼Œé™ç´šç‚º Tag æœå°‹
                cafe_tag = user_query

        # ==========================================
        # è·¯å¾‘ B: æ¨™ç±¤/åœ°ç†æœå°‹ (ä¿ç•™ä½ çš„åŸå§‹é‚è¼¯)
        # ==========================================
        if not final_data and (cafe_tag or not user_query):
            # ä½¿ç”¨è®Šæ•¸ `tag` æ¥ä½å‚³å…¥çš„ cafe_tagï¼Œæ–¹ä¾¿å°ç…§ä½ çš„ç¨‹å¼ç¢¼
            tag = cafe_tag
            if tag:
                logger.info(f"ğŸ·ï¸ [æ¨™ç±¤æœå°‹] ä½¿ç”¨è€…é»æ“ŠæŒ‰éˆ•: {tag}")           
            pipeline = []

            # (A) åœ°ç†ä½ç½®æœå°‹ (åŸºç¤) - 3kmå…§
            pipeline.append({
                "$geoNear": {
                    "near": { "type": "Point", "coordinates": [lng, lat] },
                    "distanceField": "dist_meters",
                    "maxDistance": 3000,
                    "spherical": True
                }
            })

            # (B) éæ¿¾é»‘åå–® - æ’é™¤ blacklist_ids
            if blacklist_ids:
                pipeline.append({
                    "$match": { "place_id": { "$nin": blacklist_ids } }
                })

            # (C) å¤šæ¬„ä½æ¨¡ç³Šæœå°‹ - æª¢æŸ¥æ¬„ä½ï¼Œä»»ä¸€æ¬„ä½åŒ…å«é—œéµå­—ï¼ˆä¸åˆ†å¤§å°å¯«ï¼‰å³ç¬¦åˆ
            if tag:
                pipeline.append({
                    "$match": {
                        "$or": [
                            { "original_name": { "$regex": tag, "$options": "i" } },
                            { "attributes.types": { "$regex": tag, "$options": "i" } },
                            { "ai_tags.tag": { "$regex": tag, "$options": "i" } },
                            # ä¹Ÿå¯ä»¥è£œä¸Š seo_tags
                            { "seo_tags": { "$regex": tag, "$options": "i" } }
                        ]
                    }
                })

            # (D) æ¬Šé‡æ’åº 
            pipeline.append({
                "$addFields": {
                    "search_score": {
                        "$divide": [
                            { "$ifNull": ["$rating", 0] },
                            { "$add": [{ "$divide": ["$dist_meters", 100] }, 1] }
                        ]
                    }
                }
            })
            pipeline.append({ "$sort": { "search_score": -1 } })
            pipeline.append({ "$limit": 10 })
            final_data = list(db['cafes'].aggregate(pipeline))

        # --- æœ€çµ‚æ ¼å¼åŒ– ---
        formatted_response = []
        for r in final_data:
            formatted_response.append({
                "place_id": r.get("place_id", str(r.get("_id"))),
                "original_name": r.get("original_name", "æœªçŸ¥åº—å®¶"),
                "dist_meters": int(r.get("dist_meters", 0)),
                "rating": r.get("rating", 0),
                "ai_tags": r.get("ai_tags", [])[:3],
                "match_reason": r.get("matched_review", "ç¬¦åˆæ¢ä»¶")
            })
        return {"data": formatted_response}


    except Exception as e:
        logger.error(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))



# 2. å„²å­˜ä½¿ç”¨è€…ä½ç½® (Update Location)
@app.post("/users/{user_id}/location")
def update_user_location(user_id: str, loc: UserLocation):
    try:
        db = db_client.get_db()
        collection = db['users']
        
        collection.update_one(
            {"user_id": user_id},
            {"$set": {
                "lat": loc.lat,
                "lng": loc.lng,
                "updated_at": datetime.now()
            }},
            upsert=True # è‹¥ç„¡è³‡æ–™å‰‡æ–°å¢
        )
        return {"status": "success", "message": "Location updated"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# 3. è®€å–ä½¿ç”¨è€…ä½ç½® (Get Location)
@app.get("/users/{user_id}/location")
def get_user_location(user_id: str):
    db = db_client.get_db()
    user_loc = db['users'].find_one({"user_id": user_id})
    
    if not user_loc:
        raise HTTPException(status_code=404, detail="Location not found")
        
    return {
        "lat": user_loc["lat"],
        "lng": user_loc["lng"]
    }

# 4. è¨˜éŒ„ä½¿ç”¨è€…å›é¥‹ (Log Action)
@app.post("/log_user_action")
def log_action(log_data: UserLog):
    try:
        db = db_client.get_db()
        collection = db['interaction_logs']
        
        doc = log_data.dict()
        doc['created_at_server'] = datetime.now()
        
        collection.insert_one(doc)
        return {"status": "success"}
    except Exception as e:
        return {"status": "error", "detail": str(e)}

# 5. æª¢æŸ¥ä½¿ç”¨è€…æ˜¯å¦å­˜åœ¨ (Check Profile)
@app.get("/users/{user_id}/profile")
def check_user_profile(user_id: str):
    db = db_client.get_db()
    # æª¢æŸ¥æ˜¯å¦æœ‰éä»»ä½•äº’å‹•ç´€éŒ„æˆ–ä½ç½®ç´€éŒ„
    user_exists = db['interaction_logs'].find_one({"user_id": user_id})
    
    if user_exists:
        return {"status": "success", "message": "è€æ‰‹ç”¨æˆ¶"}
    else:
        # å›å‚³ 404 ä»£è¡¨æ–°æ‰‹
        raise HTTPException(status_code=404, detail="New User")

# é¦–é æ¸¬è©¦
@app.get("/")
def read_root():
    return {"message": "API v2.0 é‹ä½œæ­£å¸¸"}